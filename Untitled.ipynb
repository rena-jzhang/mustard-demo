{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59241ff3",
   "metadata": {},
   "source": [
    "### Display dataset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbf0b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 2]\n",
      "[1 1 2 6]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([1, 2, 2, 6])\n",
    "print(le.transform([1, 1, 2, 6]))\n",
    "print(le.inverse_transform([0, 0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26be9853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/jingyiz4/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f07e3d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 50257])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "744c7691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /work/jingyiz4/miniconda3/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.20.2 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.36.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m file_path \u001b[38;5;241m=\u001b[39m files[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Read the CSV file into a DataFrame\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# display(df.head())\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Get the column names\u001b[39;00m\n\u001b[1;32m     34\u001b[0m columns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Specify the directory where your CSV files are located\n",
    "directory = '/results/twoertwe/meta/'\n",
    "\n",
    "# Create an empty DataFrame to store column information\n",
    "column_info = pd.DataFrame(columns=['File', 'Columns', 'FeatNum', 'Unique Y Values'])\n",
    "\n",
    "# Create a dictionary to group files by their prefixes\n",
    "file_groups = defaultdict(list)\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        prefix = filename.split('_')[0]\n",
    "        \n",
    "        # Add the file to the corresponding group\n",
    "        file_groups[prefix].append(file_path)\n",
    "\n",
    "# Iterate through each group and analyze one CSV file from each group\n",
    "for prefix, files in file_groups.items():\n",
    "    # Take the first file from the group (you can modify this logic if needed)\n",
    "    file_path = files[0]\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # display(df.head())\n",
    "    # Get the column names\n",
    "    columns = df.columns.tolist()\n",
    "    \n",
    "    unique_y_values = df['y'].unique().tolist()\n",
    "    \n",
    "    # Add file and column information to the DataFrame\n",
    "    column_info = pd.concat([column_info, pd.DataFrame({'File': [file_path.split('_')[0]], 'Columns': [columns], 'FeatNum': [len(columns)], 'Unique Y Values':[unique_y_values]})], ignore_index=True)\n",
    "\n",
    "grouped_info_data = []\n",
    "\n",
    "# Iterate through each row in column_info\n",
    "for _, row in column_info.iterrows():\n",
    "    file = row['File']\n",
    "    columns = row['Columns']\n",
    "    \n",
    "    # Create a dictionary to store the grouped columns\n",
    "    grouped_columns = {}\n",
    "    \n",
    "    # Iterate through each column and group by prefix\n",
    "    for col in columns:\n",
    "        prefix = col.split('_')[0]\n",
    "        if prefix in grouped_columns:\n",
    "            grouped_columns[prefix].append(col)\n",
    "        else:\n",
    "            grouped_columns[prefix] = [col]\n",
    "            \n",
    "    print(grouped_columns.items())\n",
    "    \n",
    "    # Add the grouped columns and prefix to the list\n",
    "    grouped_info_data.append({'File': file, 'GroupedColumns': list(zip(grouped_columns.keys(), [len(i) for i in grouped_columns.values()]))})\n",
    "\n",
    "grouped_info = pd.DataFrame(grouped_info_data)\n",
    "merged_info = pd.merge(column_info, grouped_info, on='File')\n",
    "\n",
    "display(merged_info)\n",
    "merged_info.to_csv('metadata.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441baec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y  meta  acoustic  language  vision  ecg  eda  mocap\n",
      "0  1     4       140       457     125    0    0      0\n",
      "1  1     3       140       457     125    0    0      0\n",
      "2  1     8       140       457     125    0    0      0\n",
      "3  1     9        52       457     125    0    0      0\n",
      "4  1     3       140         0     125   54   62      0\n",
      "5  1    19       140       457     125    0    0    330\n",
      "6  1     1         0         0      49   18    8      0\n",
      "7  1     3       140       457     125    0    0      0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Columns</th>\n",
       "      <th>FeatNum</th>\n",
       "      <th>Unique Y Values</th>\n",
       "      <th>GroupedColumns</th>\n",
       "      <th>y</th>\n",
       "      <th>meta</th>\n",
       "      <th>acoustic</th>\n",
       "      <th>language</th>\n",
       "      <th>vision</th>\n",
       "      <th>ecg</th>\n",
       "      <th>eda</th>\n",
       "      <th>mocap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/results/twoertwe/meta/mosi</td>\n",
       "      <td>[y, meta_clip, meta_begin, meta_end, meta_id, ...</td>\n",
       "      <td>727</td>\n",
       "      <td>[-2.8, -2.6, -0.8, 1.6, -2.2, -3.0, -0.4, 0.8,...</td>\n",
       "      <td>[(y, 1), (meta, 4), (acoustic, 140), (language...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/results/twoertwe/meta/sewa</td>\n",
       "      <td>[y, meta_begin, meta_end, meta_id, acoustic_op...</td>\n",
       "      <td>726</td>\n",
       "      <td>[0.0055897776, 0.41614386, 0.3779384, 0.350838...</td>\n",
       "      <td>[(y, 1), (meta, 3), (acoustic, 140), (language...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/results/twoertwe/meta/tpot</td>\n",
       "      <td>[y, meta_Evidence, meta_Visual, meta_Language,...</td>\n",
       "      <td>731</td>\n",
       "      <td>[0, 3, 2, 1]</td>\n",
       "      <td>[(y, 1), (meta, 8), (acoustic, 140), (language...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>140</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/results/twoertwe/meta/umeme</td>\n",
       "      <td>[y, meta_arousal_audio, meta_valence_audio, me...</td>\n",
       "      <td>644</td>\n",
       "      <td>[4.7, 2.55, 3.06, 5.31, 3.31, 2.85, 3.5, 4.23,...</td>\n",
       "      <td>[(y, 1), (meta, 9), (acoustic, 52), (language,...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/results/twoertwe/meta/recola</td>\n",
       "      <td>[y, meta_begin, meta_end, meta_id, acoustic_op...</td>\n",
       "      <td>385</td>\n",
       "      <td>[0.024066666, -0.0049866666, 0.060946666, 0.10...</td>\n",
       "      <td>[(y, 1), (meta, 3), (acoustic, 140), (ecg, 54)...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/results/twoertwe/meta/iemocap</td>\n",
       "      <td>[y, meta_begin, meta_end, meta_arousal_T, meta...</td>\n",
       "      <td>1072</td>\n",
       "      <td>[2.0, 3.0, 3.5, 4.0, 2.5, 4.5, 1.5, 1.6667, 2....</td>\n",
       "      <td>[(y, 1), (meta, 19), (acoustic, 140), (languag...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>140</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/results/twoertwe/meta/vreed</td>\n",
       "      <td>[y, meta_id, ecg_Bpm, ecg_HF, ecg_Ibi, ecg_LF,...</td>\n",
       "      <td>77</td>\n",
       "      <td>[1, 0, 3, 2]</td>\n",
       "      <td>[(y, 1), (meta, 1), (ecg, 18), (eda, 8), (visi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/results/twoertwe/meta/mosei</td>\n",
       "      <td>[y, meta_begin, meta_end, meta_id, acoustic_op...</td>\n",
       "      <td>726</td>\n",
       "      <td>[0.0, 1.6666666, 1.3333334, 0.33333334, 0.6666...</td>\n",
       "      <td>[(y, 1), (meta, 3), (acoustic, 140), (language...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             File  \\\n",
       "0     /results/twoertwe/meta/mosi   \n",
       "1     /results/twoertwe/meta/sewa   \n",
       "2     /results/twoertwe/meta/tpot   \n",
       "3    /results/twoertwe/meta/umeme   \n",
       "4   /results/twoertwe/meta/recola   \n",
       "5  /results/twoertwe/meta/iemocap   \n",
       "6    /results/twoertwe/meta/vreed   \n",
       "7    /results/twoertwe/meta/mosei   \n",
       "\n",
       "                                             Columns FeatNum  \\\n",
       "0  [y, meta_clip, meta_begin, meta_end, meta_id, ...     727   \n",
       "1  [y, meta_begin, meta_end, meta_id, acoustic_op...     726   \n",
       "2  [y, meta_Evidence, meta_Visual, meta_Language,...     731   \n",
       "3  [y, meta_arousal_audio, meta_valence_audio, me...     644   \n",
       "4  [y, meta_begin, meta_end, meta_id, acoustic_op...     385   \n",
       "5  [y, meta_begin, meta_end, meta_arousal_T, meta...    1072   \n",
       "6  [y, meta_id, ecg_Bpm, ecg_HF, ecg_Ibi, ecg_LF,...      77   \n",
       "7  [y, meta_begin, meta_end, meta_id, acoustic_op...     726   \n",
       "\n",
       "                                     Unique Y Values  \\\n",
       "0  [-2.8, -2.6, -0.8, 1.6, -2.2, -3.0, -0.4, 0.8,...   \n",
       "1  [0.0055897776, 0.41614386, 0.3779384, 0.350838...   \n",
       "2                                       [0, 3, 2, 1]   \n",
       "3  [4.7, 2.55, 3.06, 5.31, 3.31, 2.85, 3.5, 4.23,...   \n",
       "4  [0.024066666, -0.0049866666, 0.060946666, 0.10...   \n",
       "5  [2.0, 3.0, 3.5, 4.0, 2.5, 4.5, 1.5, 1.6667, 2....   \n",
       "6                                       [1, 0, 3, 2]   \n",
       "7  [0.0, 1.6666666, 1.3333334, 0.33333334, 0.6666...   \n",
       "\n",
       "                                      GroupedColumns  y  meta  acoustic  \\\n",
       "0  [(y, 1), (meta, 4), (acoustic, 140), (language...  1     4       140   \n",
       "1  [(y, 1), (meta, 3), (acoustic, 140), (language...  1     3       140   \n",
       "2  [(y, 1), (meta, 8), (acoustic, 140), (language...  1     8       140   \n",
       "3  [(y, 1), (meta, 9), (acoustic, 52), (language,...  1     9        52   \n",
       "4  [(y, 1), (meta, 3), (acoustic, 140), (ecg, 54)...  1     3       140   \n",
       "5  [(y, 1), (meta, 19), (acoustic, 140), (languag...  1    19       140   \n",
       "6  [(y, 1), (meta, 1), (ecg, 18), (eda, 8), (visi...  1     1         0   \n",
       "7  [(y, 1), (meta, 3), (acoustic, 140), (language...  1     3       140   \n",
       "\n",
       "   language  vision  ecg  eda  mocap  \n",
       "0       457     125    0    0      0  \n",
       "1       457     125    0    0      0  \n",
       "2       457     125    0    0      0  \n",
       "3       457     125    0    0      0  \n",
       "4         0     125   54   62      0  \n",
       "5       457     125    0    0    330  \n",
       "6         0      49   18    8      0  \n",
       "7       457     125    0    0      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_row(row):\n",
    "    # Initialize an empty dictionary to store the processed data for the row\n",
    "    processed_data = {}\n",
    "    \n",
    "    # Iterate through each cell in the row\n",
    "    for cell in row:\n",
    "        if cell:  # Check if the cell is not empty\n",
    "            column_name = cell[0]  # The first element is the column name\n",
    "            column_value = cell[1]  # Combine the other elements\n",
    "            processed_data[column_name] = column_value\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'col' is the column name\n",
    "# Apply the function to each row\n",
    "processed_rows = merged_info.GroupedColumns.apply(process_row)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(processed_rows.tolist())\n",
    "\n",
    "# If necessary, you can fill NaN values with an appropriate value or method\n",
    "result_df = result_df.fillna(0).astype(int)\n",
    "print(result_df)\n",
    "\n",
    "merged_result = merged_info.merge(\n",
    "result_df.fillna(0), left_index=True, right_index=True)\n",
    "\n",
    "display(merged_result)\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['Columns', 'FeatNum','GroupedColumns']\n",
    "\n",
    "# Remove the specified columns\n",
    "merged_result = merged_result.drop(columns=columns_to_remove)\n",
    "\n",
    "\n",
    "merged_result.to_csv('metadata.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from dataset import *\n",
    "\n",
    "# from torch.utils.data import DataLoader\n",
    "# from dataset import *\n",
    "# from mmidataset import custom_collate_fn\n",
    "\n",
    "\n",
    "# dataset_rootdir = '/results/twoertwe/meta/'  # Path to your dataset directory\n",
    "\n",
    "# batch_size = 32  # Set the batch size\n",
    "# dataset_name = 'sewa_valence'\n",
    "# data_type = 'test'\n",
    "\n",
    "# non_text_features = DATASET_MODALITY[dataset_name]\n",
    "\n",
    "# # Create an instance of MMIDataset\n",
    "# mmi_dataset = MMIDataset(data_type=data_type, dataset_name=dataset_name, \n",
    "#                         dataset_rootdir=dataset_rootdir, feature_list=non_text_features)\n",
    "\n",
    "# data_loader = DataLoader(mmi_dataset, batch_size=batch_size, collate_fn = custom_collate_fn)\n",
    "\n",
    "\n",
    "from tests.test_dataset_split import *\n",
    "test_dataset_train_val_test_overlap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5bb98",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def video_processor(video_path):\n",
    "    # Load pretrained ResNet-152 model\n",
    "    model = models.resnet152(pretrained=True)\n",
    "    model = torch.nn.Sequential(*(list(model.children())[:-1])) # Remove the last fully connected layer\n",
    "    model.eval()\n",
    "\n",
    "    # Video frame extraction and preprocessing\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = preprocess_frame(frame)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return torch.empty(0, 2048)  # Return an empty tensor if no frames are extracted\n",
    "\n",
    "    # Convert list of frames to tensor\n",
    "    frames_tensor = torch.stack(frames)\n",
    "    print('frame', frames_tensor)\n",
    "\n",
    "    # Feature extraction\n",
    "    with torch.no_grad():\n",
    "        features = model(frames_tensor)\n",
    "    print('features', features)\n",
    "\n",
    "    features_mean = torch.mean(features, dim=0).unsqueeze(0)\n",
    "\n",
    "    # Flatten features from [N, 2048, 1, 1] to [N, 2048]\n",
    "    features_flattened = torch.flatten(features_mean, start_dim=1)\n",
    "\n",
    "    return features_flattened\n",
    "\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return preprocess(frame)\n",
    "\n",
    "\n",
    "def process_video_data(videos_folder, video_features_path):\n",
    "    video_features = []\n",
    "\n",
    "    for filename in os.listdir(videos_folder):\n",
    "        video_path = os.path.join(videos_folder, filename)\n",
    "        video_feature = video_processor(video_path)\n",
    "        video_features.append(video_feature)\n",
    "            \n",
    "    with open(video_features_path, 'wb') as f:\n",
    "        pickle.dump(video_features, f)\n",
    "\n",
    "    print(f\"Video features saved to {video_features_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281bc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa torch numpy\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_librosa_features(path: str) -> np.ndarray:\n",
    "    y, sr = librosa.load(path)\n",
    "\n",
    "    hop_length = 512  # Set the hop length; at 22050 Hz, 512 samples ~= 23ms\n",
    "\n",
    "    # Remove vocals first\n",
    "    D = librosa.stft(y, hop_length=hop_length)\n",
    "    S_full, phase = librosa.magphase(D)\n",
    "\n",
    "    S_filter = librosa.decompose.nn_filter(S_full, aggregate=np.median, metric=\"cosine\",\n",
    "                                           width=int(librosa.time_to_frames(0.2, sr=sr)))\n",
    "\n",
    "    S_filter = np.minimum(S_full, S_filter)\n",
    "\n",
    "    margin_i, margin_v = 2, 4\n",
    "    power = 2\n",
    "    mask_v = librosa.util.softmask(S_full - S_filter, margin_v * S_filter, power=power)\n",
    "    S_foreground = mask_v * S_full\n",
    "\n",
    "    # Recreate vocal_removal y\n",
    "    new_D = S_foreground * phase\n",
    "    y = librosa.istft(new_D)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # Compute MFCC features from the raw signal\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)  # And the first-order differences (delta features)\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "    S_delta = librosa.feature.delta(S)\n",
    "\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(S=S_full)\n",
    "\n",
    "    audio_feature = np.vstack((mfcc, mfcc_delta, S, S_delta, spectral_centroid))  # combine features\n",
    "\n",
    "    # binning data\n",
    "    jump = int(audio_feature.shape[1] / 10)\n",
    "    return librosa.util.sync(audio_feature, range(1, audio_feature.shape[1], jump))\n",
    "\n",
    "def extract_audio_features(audio_file_path: str) -> torch.Tensor:\n",
    "    # Extract audio seq features using librosa\n",
    "    features = get_librosa_features(audio_file_path).T\n",
    "    \n",
    "    # avg\n",
    "    tensor_features = torch.tensor(features).mean(dim=0).unsqueeze(0)\n",
    "    return tensor_features\n",
    "\n",
    "def process_audio_data(audio_folder, audio_features_path):\n",
    "    audio_features = []\n",
    "\n",
    "    for filename in tqdm(os.listdir(audio_folder), desc=\"Processing audio files\"):\n",
    "        audio_path = os.path.join(audio_folder, filename)\n",
    "        if os.path.isfile(audio_path):\n",
    "            audio_feature = extract_audio_features(audio_path)\n",
    "            audio_features.append(audio_feature)\n",
    "\n",
    "    # Save to a pickle file\n",
    "    with open(audio_features_path, 'wb') as f:\n",
    "        pickle.dump(audio_features, f)\n",
    "    print(f\"Audio features saved to {audio_features_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined dataset paths configuration\n",
    "DATASET_PATHS = {\n",
    "    'datasets/MOSI_small': {\n",
    "        'videos_folder': '/projects/dataset_original/datasets/MOSI_small/Base_data/Videos_Segmented',\n",
    "        'audios_folder': '/projects/dataset_original/datasets/MOSI_small/Base_data/Audio_Segmented'\n",
    "    }\n",
    "\n",
    "    # Add more datasets here if needed\n",
    "}\n",
    "def prepare_dataset_paths(dataset_name):\n",
    "\n",
    "    # Check if the dataset is defined in the configuration\n",
    "    if dataset_name in DATASET_PATHS:\n",
    "        paths = DATASET_PATHS[dataset_name]\n",
    "\n",
    "        # Process video and audio data if their paths are available\n",
    "        if 'videos_folder' in paths:\n",
    "            video_features_path = f'{dataset_name}/video_features.pkl'\n",
    "            process_video_data(paths['videos_folder'], video_features_path)\n",
    "\n",
    "        if 'audios_folder' in paths:\n",
    "            audio_features_path = f'{dataset_name}/audio_features.pkl'\n",
    "            process_audio_data(paths['audios_folder'], audio_features_path)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset {dataset_name} not found in dataset paths\")\n",
    "\n",
    "# Example usage\n",
    "dataset_name = 'datasets/MOSI_small'\n",
    "# prepare_dataset_paths(dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process text and label\n",
    "# !pip install pandas --force-reinstall\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "TEXT_FEATURE_PATH = f'{dataset_name}/text_n_label.csv'\n",
    "\n",
    "csv_file_path = TEXT_FEATURE_PATH\n",
    "\n",
    "def read_text_files(folder_path, df):\n",
    "    text_list = []\n",
    "    label_list = []\n",
    "\n",
    "    filenames = [filename for filename in sorted(os.listdir(folder_path)) if filename.endswith('.txt')]\n",
    "    \n",
    "    print(filenames[:5])\n",
    "    # Iterate over all files in the given folder\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Check if it's a file and not a directory\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                # Read the content and add it to the list\n",
    "                text_list.append(file.read())\n",
    "                \n",
    "        label_list.append(df[df['filename'] == filename.split('.')[0]]['label'][0])\n",
    "\n",
    "    label_list = [f\"{float(number):.2f}\" for number in label_list]\n",
    "\n",
    "    return text_list, label_list\n",
    "\n",
    "\n",
    "def text_label_creation(text_list, label_list, csv_file_path = TEXT_FEATURE_PATH):\n",
    "\n",
    "    assert len(text_list) == len(label_list), \"Text and label lists must have the same length.\"\n",
    "\n",
    "    # Writing to csv file\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header\n",
    "        csvwriter.writerow(['text_input', 'label'])\n",
    "\n",
    "        # Write the data\n",
    "        for text, label in zip(text_list, label_list):\n",
    "            csvwriter.writerow([text, label])\n",
    "\n",
    "    print(f\"CSV file saved to {csv_file_path}\")\n",
    "    \n",
    "csv_path ='/projects/dataset_original/datasets/MOSI_small/Base_data/Labels/boundaries_sentimentint_avg.csv'\n",
    "text_folder = '/projects/dataset_original/datasets/MOSI_small/Base_data/Text_Per_Segment/Final'\n",
    "\n",
    "df = pd.read_csv(csv_path, header=None)\n",
    "headers = ['c1', 'c2', 'c3', 'filename', 'label']\n",
    "df.columns = headers\n",
    "\n",
    "text_list, label_list = read_text_files(text_folder, df)\n",
    "\n",
    "\n",
    "print(text_list[:5], label_list[:5])\n",
    "# text_label_creation(text_list, label_list, csv_file_path = TEXT_FEATURE_PATH)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654e5fd",
   "metadata": {},
   "source": [
    "### Result post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_metrics(true_values, predicted_values):\n",
    "    \"\"\"\n",
    "    Calculate CCC, RMSE, and PCC.\n",
    "    :param true_values: Array of true values\n",
    "    :param predicted_values: Array of predicted values\n",
    "    :return: Concordance Correlation Coefficient, Root Mean Squared Error, Pearson Correlation Coefficient\n",
    "    \"\"\"\n",
    "    # Convert non-numeric values to NaN\n",
    "    true_values = pd.to_numeric(true_values, errors='coerce')\n",
    "    predicted_values = pd.to_numeric(predicted_values, errors='coerce')\n",
    "    \n",
    "    # Remove or impute NaNs (or use np.nanmean, np.nanvar, etc., to handle NaNs)\n",
    "    valid_indices = ~np.isnan(true_values) & ~np.isnan(predicted_values)\n",
    "    true_values = true_values[valid_indices]\n",
    "    predicted_values = predicted_values[valid_indices]\n",
    "\n",
    "    # Calculate CCC\n",
    "    mean_true = np.mean(true_values)\n",
    "    mean_predicted = np.mean(predicted_values)\n",
    "    var_true = np.var(true_values)\n",
    "    var_predicted = np.var(predicted_values)\n",
    "    pearson_corr, _ = pearsonr(true_values, predicted_values)\n",
    "    ccc = (2 * pearson_corr * np.sqrt(var_true) * np.sqrt(var_predicted)) / \\\n",
    "          (var_true + var_predicted + (mean_true - mean_predicted) ** 2)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "\n",
    "    # PCC is the Pearson Correlation Coefficient\n",
    "    pcc = pearson_corr\n",
    "\n",
    "    return ccc, rmse, pcc\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "ALL_DATASETS = [\n",
    "            'umeme_arousal', \n",
    "                # 'vreed_av',\n",
    "\n",
    "                'iemocap_valence', 'iemocap_arousal',\n",
    "                # 'recola_valence', \n",
    "                # 'recola_arousal', \n",
    "                # 'sewa_valence', 'sewa_arousal', \n",
    "                # 'mosi_sentiment',\n",
    "                # 'mosei_sentiment', 'mosei_happiness',\n",
    "                ]\n",
    "\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "num_epoch = 30\n",
    "\n",
    "for task_name in ALL_DATASETS:\n",
    "    best_ccc = -1\n",
    "    best_rmse = float('inf')\n",
    "    best_pcc = -1\n",
    "\n",
    "    for i in range(num_epoch):\n",
    "        csv_file = f'/work/jingyiz4/mustard-demo/results/{task_name}/gpt2_nopretrain_0.0001_2_42_0_unfreeze/predictions_actuals_{i}.csv'\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Assuming the columns are named 'Actual' and 'Prediction'\n",
    "        true_values = df['Actual'].to_numpy()\n",
    "        predicted_values = df['Prediction'].to_numpy()\n",
    "\n",
    "        # Calculate metrics\n",
    "        ccc, rmse, pcc = calculate_metrics(true_values, predicted_values)\n",
    "\n",
    "        # Update best metrics if current epoch is better\n",
    "        if ccc > best_ccc:\n",
    "            best_ccc = ccc\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "        if pcc > best_pcc:\n",
    "            best_pcc = pcc\n",
    "\n",
    "    # Store best results for the task\n",
    "    results.append({\n",
    "        \"Task\": task_name,\n",
    "        \"Modeling\": 'gpt2',\n",
    "        \"Best RMSE\": best_rmse,\n",
    "        \"Best PCC\": best_pcc,\n",
    "        \"Best CCC\": best_ccc,\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42c6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the base directories\n",
    "source_base = \"/projects/dataset_processed\"\n",
    "target_base = \"/work/jingyiz4/datasets/\"\n",
    "# for subdir in subdirs:\n",
    "#     source_dir = os.path.join(source_base, subdir, \"twoertwein\")\n",
    "#     target_dir = os.path.join(target_base, subdir, \"twoertwein\")\n",
    "\n",
    "#     # Create the target directory if it doesn't exist\n",
    "#     os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "#     # Copy all Python files\n",
    "#     for file in os.listdir(source_dir):\n",
    "#         # if file.endswith(\".hdf\"):\n",
    "\n",
    "#         # if file.endswith(\".py\"):\n",
    "#             shutil.copy2(os.path.join(source_dir, file), target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "641fa4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   Your dog is insane\n",
       "1                  I am going shopping\n",
       "2    That’s it the meeting is finished\n",
       "4     The floor was completely covered\n",
       "5     The floor was completely covered\n",
       "Name: sentence, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0                           ANYHOW IT WAS REALLY GOOD \n",
       "1    THAY DID THEY DIDNT REALLY DO A WHOLE BUNCH OF...\n",
       "2                  I MEAN THEY DID A LITTLE BIT OF IT \n",
       "3                               BUT NOT A WHOLE BUNCH \n",
       "4                           AND THEY SHOULDVE I GUESS \n",
       "Name: sentence, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    some things in certain areas certain fields yo...\n",
       "1    yourself but in speeches it's a good thing it'...\n",
       "2    repeat something especially something that you...\n",
       "3    to get you can make statements like now we've ...\n",
       "4    with repetition it helps your audience it keep...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1653                                         laughter\n",
       "1654                                            Hello\n",
       "1655                                         laughter\n",
       "1656    Do we only have a certain amount of time now?\n",
       "2468                                                 \n",
       "Name: sentence, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0                         You seem kind of down.\n",
       "1                                      How come?\n",
       "2                              What do you mean?\n",
       "3      There's a lot of people looking for jobs.\n",
       "4    I don't know, I mean, I just don't think...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from python_tools import caching\n",
    "from python_tools.features import (\n",
    "    aggregate_to_intervals,\n",
    "    apply_masking,\n",
    "    suggest_statistics,\n",
    "    synchronize_sequences,\n",
    ")\n",
    "from python_tools.generic import map_parallel\n",
    "from python_tools.ml.data_loader import DataLoader\n",
    "from python_tools.ml.markers import get_markers\n",
    "from python_tools.ml.pytorch_tools import dict_to_batched_data\n",
    "from python_tools.ml.split import stratified_splits\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def align(\n",
    "    name_intervals: tuple[str, pd.DataFrame],\n",
    "    folder: Path,\n",
    "    skip_opensmile_stats: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    name, intervals = name_intervals\n",
    "    index = intervals.index\n",
    "    intervals = intervals.loc[:, [\"meta_begin\", \"meta_end\"]].values + [-0.5, 0.5]\n",
    "\n",
    "    # load raw features\n",
    "    data = {}\n",
    "    for key in (\"opensmile_eGeMAPSv02\", \"opensmile_vad_opensource\", \"openface\"):\n",
    "        tmp = caching.read_hdfs(folder / key / name)\n",
    "        if \"df\" in tmp:\n",
    "            data[key] = tmp[\"df\"]\n",
    "        else:\n",
    "            for subfeature in tmp:\n",
    "                data[f\"{key}_{subfeature}\"] = tmp[subfeature]\n",
    "    if skip_opensmile_stats:\n",
    "        data.pop(\"opensmile_eGeMAPSv02_csvoutput\")\n",
    "    data = synchronize_sequences(data, intersect=False)\n",
    "\n",
    "    # simple stats and some markers\n",
    "    data = apply_masking(data)\n",
    "    stats = suggest_statistics(data.columns.to_list())\n",
    "    feature = (\n",
    "        aggregate_to_intervals(data, intervals, stats)\n",
    "        .drop(columns=[\"begin\", \"end\"])\n",
    "        .set_index(index)\n",
    "    )\n",
    "    tmp = []\n",
    "    for begin, end in intervals:\n",
    "        interval_data = data.loc[begin:end]\n",
    "        if interval_data.empty:\n",
    "            tmp.append(None)\n",
    "        else:\n",
    "            tmp.append(get_markers(interval_data))\n",
    "    nan = {key: float(\"NaN\") for key in next(x for x in tmp if x is not None)}\n",
    "    tmp = [nan if x is None else x for x in tmp]\n",
    "    tmp = pd.DataFrame(tmp, index=index)\n",
    "    result = (\n",
    "        pd.concat(\n",
    "            [feature, tmp.loc[:, tmp.columns.difference(feature.columns)]],\n",
    "            axis=1,\n",
    "        )\n",
    "        .fillna(method=\"ffill\")\n",
    "        .fillna(method=\"bfill\")\n",
    "    )\n",
    "    return result.rename(\n",
    "        columns={x: f\"vision_{x}\" for x in result.columns if x.startswith(\"openface\")}\n",
    "        | {x: f\"acoustic_{x}\" for x in result.columns if x.startswith(\"opensmile\")}\n",
    "        | {\"duchenne_smile_ratio\": \"vision_duchenne_smile_ratio\"}\n",
    "    )\n",
    "\n",
    "\n",
    "def read_df_from_hdf(task_name):\n",
    "    file_path = f\"/work/jingyiz4/datasets/{task_name}/twoertwein/all_minilm_l12_v2.hdf\"\n",
    "\n",
    "    # Read the dataframe from the HDF file\n",
    "    try:\n",
    "        stored_df = pd.read_hdf(file_path, key='df')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the HDF file: {e}\")\n",
    "    meta_strings_filtered = [\n",
    "        string for string in stored_df.columns \n",
    "        if 'liwc_' not in string and 'all_minilm_' not in string \n",
    "    ]    \n",
    "\n",
    "    # display(meta_strings_filtered)\n",
    "    # display(stored_df[meta_strings_filtered].head(5))\n",
    "    # print(len(stored_df))\n",
    "    return stored_df[meta_strings_filtered]\n",
    "    \n",
    "def process_ds_df(df):\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"begin\": \"meta_begin\",\n",
    "                \"end\": \"meta_end\",\n",
    "                \"clip\": \"meta_clip\",\n",
    "                \"meta_id\": \"name\",\n",
    "            }\n",
    "        )\n",
    "        df[\"meta_id\"] = pd.Categorical(df[\"name\"]).codes\n",
    "\n",
    "        if \"file\" in df.columns:  # for IEMOCAP and UMEME\n",
    "            df[\"file\"] = df[\"file\"].apply(\n",
    "                lambda x: x.split(\".\", 1)[0]\n",
    "            )\n",
    "            df[\"name\"] = df[\"file\"]\n",
    "\n",
    "        if \"meta_begin\" not in df:\n",
    "            df[\"meta_begin\"] = 0.0\n",
    "            df[\"meta_end\"] = 60.0\n",
    "        df = pd.concat([df, align_features()], axis=1).astype(\n",
    "            np.float32, errors=\"ignore\"\n",
    "        )\n",
    "        df[\"meta_id\"] = df[\"meta_id\"].astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "# List of subdrectories\n",
    "datasets = {\n",
    "    \"UMEME\": 'umeme', # done\n",
    "    \"MOSI\": 'mosi',\n",
    "    \"MOSEI\": 'mosei', # sentence merge issue\n",
    "    # \"AVEC16-RECOLA\": 'recola', #done\n",
    "    \n",
    "    \"SEWA\": 'sewa',\n",
    "    \"IEMOCAP\": 'iemocap'  # Uncomment if needed\n",
    "}\n",
    "\n",
    "dataset_rootdir = '/results/twoertwe/meta/'  # Path to your dataset directory\n",
    "new_dataset_rootdir = '/work/jingyiz4/cleaned_data/'\n",
    "\n",
    "# Assuming the HDF file is \"all_minilm_l12_v2.hdf\" and the key for the dataframe is \"df\"\n",
    "for dataset, dataset_abbr in datasets.items():\n",
    "    ds_df = read_df_from_hdf(dataset)\n",
    "    display(ds_df['sentence'].head())\n",
    "    continue\n",
    "\n",
    "    ds_df = process_ds_df(ds_df)\n",
    "\n",
    "    # List all files in dataset_dir\n",
    "    all_files = os.listdir(dataset_rootdir)\n",
    "\n",
    "    # Filter for CSV files that include 'dataset' in their name\n",
    "    csv_files = [file for file in all_files if dataset_abbr in file and file.endswith('.csv')]\n",
    "\n",
    "    print(csv_files)\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        csv_path = os.path.join(dataset_rootdir, csv_file)\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # remove old text columns, now both dfs are cleaned\n",
    "        non_emb_col = [\n",
    "            string for string in df.columns \n",
    "            if 'liwc_' not in string and 'all_minilm_' not in string \n",
    "        ]    \n",
    "        df = df[non_emb_col]\n",
    "\n",
    "        # Append 'sentence' column from ds_df to df\n",
    "        # Ensure the 'sentence' column exists in ds_df\n",
    "        if 'sentence' in ds_df.columns:\n",
    "            # Find shared columns\n",
    "            shared_cols = list(set(ds_df.columns).intersection(set(df.columns)))\n",
    "            print(f\"Dataset: {dataset}\")\n",
    "            shared_cols =  ['meta_begin', 'meta_end',  'meta_id']\n",
    "            print(f\"Columns in ds_df: {ds_df.columns.tolist()}\")\n",
    "            print(f\"Columns in df: {df.columns.tolist()}\")\n",
    "            print(len(ds_df), len(df))\n",
    "            \n",
    "            print(f\"Shared columns: {shared_cols}\")\n",
    "            display(ds_df.head())   \n",
    "            display(df.head())   \n",
    "\n",
    "            print()\n",
    "            \n",
    "            ds_keys = shared_cols\n",
    "            df_keys = shared_cols\n",
    "\n",
    "            ds_df['key'] = ds_df[ds_keys].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "            df['key'] = df[df_keys].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "            display(ds_df['key'].head())\n",
    "            display(df['key'].head())   \n",
    "\n",
    "            new_df = df.merge(ds_df[['key', 'sentence']], on='key', how='left')\n",
    "            new_df.drop('key', inplace=True, axis=1)\n",
    "            display(ds_df['sentence'].head())\n",
    "            display(new_df['sentence'].head())\n",
    "        else:\n",
    "            new_df = df.copy()\n",
    "\n",
    "        assert len(new_df) == len(df)\n",
    "\n",
    "        break\n",
    "        # new_df.to_csv(os.path.join(new_dataset_rootdir, csv_file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sys.path.append(\"/results/twoertwe/emro\")\n",
    "\n",
    "from dataloader import get_partitions\n",
    "\n",
    "\n",
    "for dataset, labels in (\n",
    "    # regression\n",
    "    # (\"mosi\", (\"sentiment\",)),\n",
    "    # (\"mosei\", (\"sentiment\", \"happiness\")),\n",
    "    # (\"sewa\", (\"arousal\", \"valence\")),\n",
    "    # (\"recola\", (\"arousal\", \"valence\")),\n",
    "    # (\"iemocap\", (\"arousal\", \"valence\")),\n",
    "    (\"umeme\", (\"arousal\", \"valence\")),\n",
    "    # # classification (4 classes)\n",
    "    # (\"tpot\", (\"constructs\",)),\n",
    "    # # classification (5 classes)\n",
    "    # (\"vreed\", (\"av\",)),\n",
    "):\n",
    "    for label in labels:\n",
    "        # get 5-fold\n",
    "        for fold, partition in get_partitions(\n",
    "            f\"{dataset}/{label}\", batch_size=-1\n",
    "        ).items():\n",
    "            # training, validation, test sets\n",
    "            for name, data in partition.items():\n",
    "                assert len(data.iterator) == 1\n",
    "                features = pd.DataFrame(\n",
    "                    data.iterator[0].pop(\"x\")[0],\n",
    "                    columns=data.properties[\"x_names\"],\n",
    "                )\n",
    "                labels_metadata = pd.DataFrame(\n",
    "                    {key: value[0][:, 0] for key, value in data.iterator[0].items()}\n",
    "                )\n",
    "                final_csv = pd.concat([labels_metadata, features], axis=1)\n",
    "                display(final_csv.head())\n",
    "                break\n",
    "                # final_csv.to_csv(\n",
    "                #     f\"{dataset}_{label}_{fold}_{name}.csv\", index=False\n",
    "                # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9482e828",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'FeatureExtraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/work/jingyiz4/miniconda3/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/work/jingyiz4/miniconda3/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_2095786/1794286718.py\", line 22, in extract\n    features.extract_features(video=file, audio=file, caches=cache)\n  File \"/work/jingyiz4/mustard-demo/python_tools/features.py\", line 546, in extract_features\n    datum = run_openface(video, cache=caches[key], **kwargs[key])\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/jingyiz4/mustard-demo/python_tools/caching.py\", line 190, in wrapper\n    result = function(*args, cache=cache, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/jingyiz4/mustard-demo/python_tools/features.py\", line 411, in run_openface\n    returncode, _, error = generic.run(command, stdout=None)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/work/jingyiz4/mustard-demo/python_tools/generic.py\", line 136, in run\n    with subprocess.Popen(\n         ^^^^^^^^^^^^^^^^^\n  File \"/work/jingyiz4/miniconda3/lib/python3.11/subprocess.py\", line 1026, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/work/jingyiz4/miniconda3/lib/python3.11/subprocess.py\", line 1950, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'FeatureExtraction'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m     features\u001b[38;5;241m.\u001b[39mextract_features(video\u001b[38;5;241m=\u001b[39mfile, audio\u001b[38;5;241m=\u001b[39mfile, caches\u001b[38;5;241m=\u001b[39mcache)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mmap_parallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextract\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/projects/dataset_original/UMEME/media/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.mp*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can I not\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI’m quite sure that we will find some way or another\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly I joined her in the ceremony\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     58\u001b[0m     }\n",
      "File \u001b[0;32m/work/jingyiz4/mustard-demo/python_tools/generic.py:56\u001b[0m, in \u001b[0;36mmap_parallel\u001b[0;34m(function, elements, workers, chunksize)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mworkers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 56\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(function, elements))\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/multiprocessing/pool.py:48\u001b[0m, in \u001b[0;36mmapstar\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmapstar\u001b[39m(args):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;241m*\u001b[39margs))\n",
      "Cell \u001b[0;32mIn[19], line 22\u001b[0m, in \u001b[0;36mextract\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopensmile_eGeMAPSv02\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopensmile_eGeMAPSv02/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m     cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopensmile_vad_opensource\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopensmile_vad_opensource/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m features\u001b[38;5;241m.\u001b[39mextract_features(video\u001b[38;5;241m=\u001b[39mfile, audio\u001b[38;5;241m=\u001b[39mfile, caches\u001b[38;5;241m=\u001b[39mcache)\n",
      "File \u001b[0;32m/work/jingyiz4/mustard-demo/python_tools/features.py:546\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m()\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m key:\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenface\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 546\u001b[0m         datum \u001b[38;5;241m=\u001b[39m run_openface(video, cache\u001b[38;5;241m=\u001b[39mcaches[key], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[key])\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovarep\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    548\u001b[0m         datum \u001b[38;5;241m=\u001b[39m run_covarep(audio, cache\u001b[38;5;241m=\u001b[39mcaches[key], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[key])\n",
      "File \u001b[0;32m/work/jingyiz4/mustard-demo/python_tools/caching.py:190\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# run/save\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m result \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39margs, cache\u001b[38;5;241m=\u001b[39mcache, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    192\u001b[0m     write_hdfs(cache, result)\n",
      "File \u001b[0;32m/work/jingyiz4/mustard-demo/python_tools/features.py:411\u001b[0m, in \u001b[0;36mrun_openface\u001b[0;34m()\u001b[0m\n\u001b[1;32m    405\u001b[0m command \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../OpenFace/exe/FeatureExtraction/FeatureExtraction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -out_dir \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m )\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# run OpenFace\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m returncode, _, error \u001b[38;5;241m=\u001b[39m generic\u001b[38;5;241m.\u001b[39mrun(command, stdout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    412\u001b[0m detail_file \u001b[38;5;241m=\u001b[39m output_folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_of_details.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m detail_file\u001b[38;5;241m.\u001b[39munlink(missing_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/work/jingyiz4/mustard-demo/python_tools/generic.py:136\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stderr \u001b[38;5;241m==\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE:\n\u001b[1;32m    134\u001b[0m     stderr \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mTemporaryFile(buffering\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[1;32m    137\u001b[0m     command,\n\u001b[1;32m    138\u001b[0m     stdout\u001b[38;5;241m=\u001b[39mstdout,\n\u001b[1;32m    139\u001b[0m     stderr\u001b[38;5;241m=\u001b[39mstderr,\n\u001b[1;32m    140\u001b[0m     stdin\u001b[38;5;241m=\u001b[39mstdin,\n\u001b[1;32m    141\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    144\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/subprocess.py:1026\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[1;32m   1032\u001b[0m                         restore_signals,\n\u001b[1;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/subprocess.py:1950\u001b[0m, in \u001b[0;36m_execute_child\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1949\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1950\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1951\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'FeatureExtraction'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from python_tools import caching, features\n",
    "from python_tools.generic import map_parallel\n",
    "\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(0, \"/projects/dataset_processed/TPOT/twoertwein\")\n",
    "from python_tools.extract import extract_liwc, load_liwc\n",
    "\n",
    "\n",
    "def extract(file: Path) -> None:\n",
    "    name = file.with_suffix(\".hdf\").name\n",
    "    # openface+opensmile\n",
    "    cache = {}\n",
    "    if file.suffix == \".mp4\":\n",
    "        cache[\"openface\"] = Path(f\"openface/{name}\")\n",
    "    if file.suffix == \".mp3\" or \"Only\" not in file.name:\n",
    "        cache[\"opensmile_eGeMAPSv02\"] = Path(f\"opensmile_eGeMAPSv02/{name}\")\n",
    "        cache[\"opensmile_vad_opensource\"] = Path(f\"opensmile_vad_opensource/{name}\")\n",
    "    features.extract_features(video=file, audio=file, caches=cache)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    map_parallel(\n",
    "        extract,\n",
    "        Path(\"/projects/dataset_original/UMEME/media/\").glob(\"*.mp*\"),\n",
    "        workers=7,\n",
    "    )\n",
    "\n",
    "    sentences = (\n",
    "        \"How can I not\",\n",
    "        \"I’m quite sure that we will find some way or another\",\n",
    "        \"Ella Jorgenson made the pudding\",\n",
    "        \"The floor was completely covered\",\n",
    "        \"They are just going to go ahead regardless\",\n",
    "        \"It has all been scheduled since Wednesday\",\n",
    "        \"I am going shopping\",\n",
    "        \"A preliminary study shows rats to be more inquisitive than once thought\",\n",
    "        \"That’s it the meeting is finished\",\n",
    "        \"I don’t know how she could miss this opportunity\",\n",
    "        \"It is raining outside\",\n",
    "        \"Your dog is insane\",\n",
    "        \"She told me what you did\",\n",
    "        \"Your grandmother is on the phone\",\n",
    "        \"Only I joined her in the ceremony\",\n",
    "    )\n",
    "    data = {\n",
    "        \"file\": [],\n",
    "        \"name\": [],\n",
    "        \"sentence\": [],\n",
    "        \"valence\": [],\n",
    "        \"arousal\": [],\n",
    "        \"dominance\": [],\n",
    "        \"audio\": [],\n",
    "        \"video\": [],\n",
    "    }\n",
    "    for block in (\n",
    "        Path(\"/projects/dataset_original/UMEME/evaluation.txt\")\n",
    "        .read_text()\n",
    "        .split(\"\\n\\n\")\n",
    "    ):\n",
    "        if not block:\n",
    "            continue\n",
    "        name, *details = block.split(\"\\n\")\n",
    "        details = {\n",
    "            detail.split(\":\", 1)[0].strip(): detail.split(\":\", 1)[1].strip()\n",
    "            for detail in details\n",
    "        }\n",
    "\n",
    "        data[\"name\"].append(details[\"speaker\"])\n",
    "        match details[\"modality\"]:\n",
    "            case \"av\":\n",
    "                file = f\"{name}_original.mp4\"\n",
    "            case \"video\":\n",
    "                file = f\"{name}_videoOnly.mp4\"\n",
    "            case \"audio\":\n",
    "                file = f\"{name}_audioOnly.mp3\"\n",
    "            case _:\n",
    "                assert False, _\n",
    "        assert (Path(\"/projects/dataset_original/UMEME/media\") / file).is_file()\n",
    "        data[\"file\"].append(file)\n",
    "        data[\"sentence\"].append(\n",
    "            sentences[int(name.split(\"-\", 1)[0].split(\"S\", 1)[1][:-1]) - 1]\n",
    "        )\n",
    "        \n",
    "        # TODO\n",
    "        # data[\"arousal\"].append(float(details[\"act\"].split(\"+\", 1)[0]))\n",
    "        # data[\"valence\"].append(float(details[\"val\"].split(\"+\", 1)[0]))\n",
    "        # data[\"dominance\"].append(float(details[\"dom\"].split(\"+\", 1)[0]))\n",
    "        # data[\"audio\"].append(details.get(\"audio\", \"\"))\n",
    "        # data[\"video\"].append(details.get(\"video\", \"\"))\n",
    "\n",
    "    # copy labels of uni-modal ratings but discard their features\n",
    "    data = pd.DataFrame(data)\n",
    "    display(data.head())\n",
    "    unimodal = data.loc[data[\"file\"].apply(lambda x: \"Only\" in x)].copy()\n",
    "    unimodal[\"file\"] = unimodal[\"file\"].apply(lambda x: x.split(\".\")[0])\n",
    "    labels = (\"arousal\", \"valence\", \"dominance\")\n",
    "    for key in (\"audio\", \"video\"):\n",
    "        for label in labels:\n",
    "            data[f\"meta_{label}_{key}\"] = float(\"NaN\")\n",
    "    for index, row in data.iterrows():\n",
    "        if \"Only\" in row[\"file\"]:\n",
    "            continue\n",
    "        for key in (\"audio\", \"video\"):\n",
    "            match = unimodal[\"file\"] == f\"{row[key]}_{key}Only\"\n",
    "            if not match.any():\n",
    "                print(f\"{row[key]}_{key}Only\")\n",
    "                continue\n",
    "            assert match.sum() == 1\n",
    "            unimodal_index = match[match].index[0]\n",
    "\n",
    "            for label in labels:\n",
    "                data.loc[index, f\"meta_{label}_{key}\"] = unimodal.loc[\n",
    "                    unimodal_index, label\n",
    "                ]\n",
    "    data = data.loc[data[\"file\"].apply(lambda x: \"Only\" not in x)]\n",
    "\n",
    "    # model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "    # embeddings = pd.DataFrame(\n",
    "    #     model.encode(data[\"sentence\"].str.lower().tolist()), index=data.index\n",
    "    # )\n",
    "\n",
    "    liwc = load_liwc()\n",
    "    liwc_features = extract_liwc(liwc, data[\"sentence\"])\n",
    "\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            data,\n",
    "            # embeddings.add_prefix(\"all_minilm_l12_v2_\"),\n",
    "            liwc_features.add_prefix(\"liwc_\"),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    display(data.head())\n",
    "    # caching.write_hdfs(Path(\"all_minilm_l12_v2.hdf\"), {\"df\": data})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32312d5",
   "metadata": {},
   "source": [
    "### Create latex result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995663e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_grouped_latex_table(df, group_column, caption=\"Your Table Caption\", label=\"tab:your_label\"):\n",
    "    \"\"\"\n",
    "    Create a LaTeX table with grouped rows based on a specific column.\n",
    "\n",
    "    :param df: Pandas DataFrame to convert\n",
    "    :param group_column: Column name to group by\n",
    "    :param caption: Caption for the LaTeX table\n",
    "    :param label: Label for the LaTeX table\n",
    "    :return: String containing the LaTeX table code\n",
    "    \"\"\"\n",
    "    unique_groups = df[group_column].unique()\n",
    "    grouped = df.groupby(group_column)\n",
    "\n",
    "    latex_table = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\begin{tabular}{|l|l|r|r|r|}\\n\\\\hline\\n\"\n",
    "    column_labels = \" & \".join(df.columns) + \" \\\\\\\\\\n\\\\hline\\n\"\n",
    "    latex_table += column_labels\n",
    "\n",
    "    for group in unique_groups:\n",
    "        group_df = grouped.get_group(group)\n",
    "        for i, row in group_df.iterrows():\n",
    "            if i == group_df.index[0]:  # First row of the group\n",
    "                latex_table += f\"\\\\multirow{{{len(group_df)}}}{{*}}{{{row[group_column]}}}\"\n",
    "            latex_table += \" & \" + \" & \".join([str(row[col]) for col in df.columns if col != group_column])\n",
    "            latex_table += \" \\\\\\\\\\n\"\n",
    "            if i == group_df.index[-1]:  # Last row of the group\n",
    "                latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "    latex_table += \"\\\\end{tabular}\\n\"\n",
    "    latex_table += f\"\\\\caption{{{caption}}}\\n\"\n",
    "    latex_table += f\"\\\\label{{{label}}}\\n\"\n",
    "    latex_table += \"\\\\end{table}\"\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Example DataFrame\n",
    "# data = {\n",
    "#     \"Task Name\": [\"Task1\", \"Task1\", \"Task2\", \"Task2\", \"Task2\"],\n",
    "#     \"Modeling\": [\"Model A\", \"Model B\", \"Model A\", \"Model B\", \"Model C\"],\n",
    "#     \"RMSE\": [1.2, 1.3, 1.1, 1.4, 1.5],\n",
    "#     \"PCC\": [0.7, 0.75, 0.65, 0.8, 0.85],\n",
    "#     \"CCC\": [0.9, 0.85, 0.88, 0.86, 0.89]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = create_grouped_latex_table(results_df, \"Task\", caption=\"Grouped Performance Metrics\", label=\"tab:grouped_performance\")\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from python_tools import caching, features\n",
    "from python_tools.generic import map_parallel\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/projects/dataset_processed/TPOT/twoertwein\")\n",
    "from python_tools.extract import extract_liwc, load_liwc\n",
    "\n",
    "def extract(file: Path) -> None:\n",
    "    name = file.with_suffix(\".hdf\").name\n",
    "    # openface+opensmile\n",
    "    cache = {}\n",
    "    if file.suffix == \".mp4\":\n",
    "        cache[\"openface\"] = Path(f\"openface/{name}\")\n",
    "    if file.suffix == \".mp3\" or \"Only\" not in file.name:\n",
    "        cache[\"opensmile_eGeMAPSv02\"] = Path(f\"opensmile_eGeMAPSv02/{name}\")\n",
    "        cache[\"opensmile_vad_opensource\"] = Path(f\"opensmile_vad_opensource/{name}\")\n",
    "    features.extract_features(video=file, audio=file, caches=cache)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    map_parallel(\n",
    "        extract,\n",
    "        Path(\"/projects/dataset_original/UMEME/media/\").glob(\"*.mp*\"),\n",
    "        workers=7,\n",
    "    )\n",
    "\n",
    "    sentences = (\n",
    "        \"How can I not\",\n",
    "        \"I’m quite sure that we will find some way or another\",\n",
    "        \"Ella Jorgenson made the pudding\",\n",
    "        \"The floor was completely covered\",\n",
    "        \"They are just going to go ahead regardless\",\n",
    "        \"It has all been scheduled since Wednesday\",\n",
    "        \"I am going shopping\",\n",
    "        \"A preliminary study shows rats to be more inquisitive than once thought\",\n",
    "        \"That’s it the meeting is finished\",\n",
    "        \"I don’t know how she could miss this opportunity\",\n",
    "        \"It is raining outside\",\n",
    "        \"Your dog is insane\",\n",
    "        \"She told me what you did\",\n",
    "        \"Your grandmother is on the phone\",\n",
    "        \"Only I joined her in the ceremony\",\n",
    "    )\n",
    "    data = {\n",
    "        \"file\": [],\n",
    "        \"name\": [],\n",
    "        \"sentence\": [],\n",
    "        \"valence\": [],\n",
    "        \"arousal\": [],\n",
    "        \"dominance\": [],\n",
    "        \"audio\": [],\n",
    "        \"video\": [],\n",
    "    }\n",
    "    for block in (\n",
    "        Path(\"/projects/dataset_original/UMEME/evaluation.txt\")\n",
    "        .read_text()\n",
    "        .split(\"\\n\\n\")\n",
    "    ):\n",
    "        if not block:\n",
    "            continue\n",
    "        name, *details = block.split(\"\\n\")\n",
    "        details = {\n",
    "            detail.split(\":\", 1)[0].strip(): detail.split(\":\", 1)[1].strip()\n",
    "            for detail in details\n",
    "        }\n",
    "\n",
    "        data[\"name\"].append(details[\"speaker\"])\n",
    "        match details[\"modality\"]:\n",
    "            case \"av\":\n",
    "                file = f\"{name}_original.mp4\"\n",
    "            case \"video\":\n",
    "                file = f\"{name}_videoOnly.mp4\"\n",
    "            case \"audio\":\n",
    "                file = f\"{name}_audioOnly.mp3\"\n",
    "            case _:\n",
    "                assert False, _\n",
    "        assert (Path(\"/projects/dataset_original/UMEME/media\") / file).is_file()\n",
    "        data[\"file\"].append(file)\n",
    "        data[\"sentence\"].append(\n",
    "            sentences[int(name.split(\"-\", 1)[0].split(\"S\", 1)[1][:-1]) - 1]\n",
    "        )\n",
    "        data[\"arousal\"].append(float(details[\"act\"].split(\"+\", 1)[0]))\n",
    "        data[\"valence\"].append(float(details[\"val\"].split(\"+\", 1)[0]))\n",
    "        data[\"dominance\"].append(float(details[\"dom\"].split(\"+\", 1)[0]))\n",
    "        data[\"audio\"].append(details.get(\"audio\", \"\"))\n",
    "        data[\"video\"].append(details.get(\"video\", \"\"))\n",
    "\n",
    "    # copy labels of uni-modal ratings but discard their features\n",
    "    data = pd.DataFrame(data)\n",
    "    unimodal = data.loc[data[\"file\"].apply(lambda x: \"Only\" in x)].copy()\n",
    "    unimodal[\"file\"] = unimodal[\"file\"].apply(lambda x: x.split(\".\")[0])\n",
    "    labels = (\"arousal\", \"valence\", \"dominance\")\n",
    "    for key in (\"audio\", \"video\"):\n",
    "        for label in labels:\n",
    "            data[f\"meta_{label}_{key}\"] = float(\"NaN\")\n",
    "    for index, row in data.iterrows():\n",
    "        if \"Only\" in row[\"file\"]:\n",
    "            continue\n",
    "        for key in (\"audio\", \"video\"):\n",
    "            match = unimodal[\"file\"] == f\"{row[key]}_{key}Only\"\n",
    "            if not match.any():\n",
    "                print(f\"{row[key]}_{key}Only\")\n",
    "                continue\n",
    "            assert match.sum() == 1\n",
    "            unimodal_index = match[match].index[0]\n",
    "\n",
    "            for label in labels:\n",
    "                data.loc[index, f\"meta_{label}_{key}\"] = unimodal.loc[\n",
    "                    unimodal_index, label\n",
    "                ]\n",
    "    data = data.loc[data[\"file\"].apply(lambda x: \"Only\" not in x)]\n",
    "\n",
    "    # model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "    # embeddings = pd.DataFrame(\n",
    "    #     model.encode(data[\"sentence\"].str.lower().tolist()), index=data.index\n",
    "    # )\n",
    "\n",
    "    liwc = load_liwc()\n",
    "    liwc_features = extract_liwc(liwc, data[\"sentence\"])\n",
    "\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            data,\n",
    "            # embeddings.add_prefix(\"all_minilm_l12_v2_\"),\n",
    "            liwc_features.add_prefix(\"liwc_\"),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    display(data.head())\n",
    "    \n",
    "    # caching.write_hdfs(Path(\"all_minilm_l12_v2.hdf\"), {\"df\": data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cloudpickle dask distributed pympi-ling nltk beartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b06efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the HDF file is \"all_minilm_l12_v2.hdf\" and the key for the dataframe is \"df\"\n",
    "file_path = \"all_minilm_l12_v2.hdf\"\n",
    "\n",
    "# Read the dataframe from the HDF file\n",
    "try:\n",
    "    stored_df = pd.read_hdf(file_path, key='df')\n",
    "except Exception as e:\n",
    "    stored_df = f\"An error occurred while reading the HDF file: {e}\"\n",
    "\n",
    "stored_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065f336c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "Fold 1 - Train: (1099, 189) Validation: (157, 189) Test: (314, 189)\n",
      "Fold 2 - Train: (1099, 189) Validation: (157, 189) Test: (314, 189)\n",
      "Fold 3 - Train: (1099, 189) Validation: (157, 189) Test: (314, 189)\n",
      "Fold 0 - Saved training data to /work/jingyiz4/new_cleaned_data/umeme_arousal_0_training.csv\n",
      "Fold 0 - Saved validation data to /work/jingyiz4/new_cleaned_data/umeme_arousal_0_validation.csv\n",
      "Fold 0 - Saved test data to /work/jingyiz4/new_cleaned_data/umeme_arousal_0_test.csv\n",
      "Fold 1 - Saved training data to /work/jingyiz4/new_cleaned_data/umeme_arousal_1_training.csv\n",
      "Fold 1 - Saved validation data to /work/jingyiz4/new_cleaned_data/umeme_arousal_1_validation.csv\n",
      "Fold 1 - Saved test data to /work/jingyiz4/new_cleaned_data/umeme_arousal_1_test.csv\n",
      "Fold 2 - Saved training data to /work/jingyiz4/new_cleaned_data/umeme_arousal_2_training.csv\n",
      "Fold 2 - Saved validation data to /work/jingyiz4/new_cleaned_data/umeme_arousal_2_validation.csv\n",
      "Fold 2 - Saved test data to /work/jingyiz4/new_cleaned_data/umeme_arousal_2_test.csv\n",
      "Fold 3 - Saved training data to /work/jingyiz4/new_cleaned_data/umeme_arousal_3_training.csv\n",
      "Fold 3 - Saved validation data to /work/jingyiz4/new_cleaned_data/umeme_arousal_3_validation.csv\n",
      "Fold 3 - Saved test data to /work/jingyiz4/new_cleaned_data/umeme_arousal_3_test.csv\n",
      "Fold 4 - Saved training data to /work/jingyiz4/new_cleaned_data/umeme_arousal_4_training.csv\n",
      "Fold 4 - Saved validation data to /work/jingyiz4/new_cleaned_data/umeme_arousal_4_validation.csv\n",
      "Fold 4 - Saved test data to /work/jingyiz4/new_cleaned_data/umeme_arousal_4_test.csv\n",
      "1570\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "Fold 1 - Train: (1099, 189) Validation: (157, 189) Test: (314, 189)\n",
      "Fold 2 - Train: (1099, 189) Validation: (157, 189) Test: (314, 189)\n",
      "Fold 3 - Train: (1099, 189) Validation: (157, 189) Test: (314, 189)\n",
      "Fold 0 - Saved training data to /work/jingyiz4/new_cleaned_data/umeme_valence_0_training.csv\n",
      "Fold 0 - Saved validation data to /work/jingyiz4/new_cleaned_data/umeme_valence_0_validation.csv\n",
      "Fold 0 - Saved test data to /work/jingyiz4/new_cleaned_data/umeme_valence_0_test.csv\n",
      "Fold 1 - Saved training data to /work/jingyiz4/new_cleaned_data/umeme_valence_1_training.csv\n",
      "Fold 1 - Saved validation data to /work/jingyiz4/new_cleaned_data/umeme_valence_1_validation.csv\n",
      "Fold 1 - Saved test data to /work/jingyiz4/new_cleaned_data/umeme_valence_1_test.csv\n",
      "Fold 2 - Saved training data to /work/jingyiz4/new_cleaned_data/umeme_valence_2_training.csv\n",
      "Fold 2 - Saved validation data to /work/jingyiz4/new_cleaned_data/umeme_valence_2_validation.csv\n",
      "Fold 2 - Saved test data to /work/jingyiz4/new_cleaned_data/umeme_valence_2_test.csv\n",
      "Fold 3 - Saved training data to /work/jingyiz4/new_cleaned_data/umeme_valence_3_training.csv\n",
      "Fold 3 - Saved validation data to /work/jingyiz4/new_cleaned_data/umeme_valence_3_validation.csv\n",
      "Fold 3 - Saved test data to /work/jingyiz4/new_cleaned_data/umeme_valence_3_test.csv\n",
      "Fold 4 - Saved training data to /work/jingyiz4/new_cleaned_data/umeme_valence_4_training.csv\n",
      "Fold 4 - Saved validation data to /work/jingyiz4/new_cleaned_data/umeme_valence_4_validation.csv\n",
      "Fold 4 - Saved test data to /work/jingyiz4/new_cleaned_data/umeme_valence_4_test.csv\n",
      "1080\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "Fold 1 - Train: (756, 386) Validation: (108, 386) Test: (216, 386)\n",
      "Fold 2 - Train: (756, 386) Validation: (108, 386) Test: (216, 386)\n",
      "Fold 3 - Train: (756, 386) Validation: (108, 386) Test: (216, 386)\n",
      "Fold 0 - Saved training data to /work/jingyiz4/new_cleaned_data/recola_valence_0_training.csv\n",
      "Fold 0 - Saved validation data to /work/jingyiz4/new_cleaned_data/recola_valence_0_validation.csv\n",
      "Fold 0 - Saved test data to /work/jingyiz4/new_cleaned_data/recola_valence_0_test.csv\n",
      "Fold 1 - Saved training data to /work/jingyiz4/new_cleaned_data/recola_valence_1_training.csv\n",
      "Fold 1 - Saved validation data to /work/jingyiz4/new_cleaned_data/recola_valence_1_validation.csv\n",
      "Fold 1 - Saved test data to /work/jingyiz4/new_cleaned_data/recola_valence_1_test.csv\n",
      "Fold 2 - Saved training data to /work/jingyiz4/new_cleaned_data/recola_valence_2_training.csv\n",
      "Fold 2 - Saved validation data to /work/jingyiz4/new_cleaned_data/recola_valence_2_validation.csv\n",
      "Fold 2 - Saved test data to /work/jingyiz4/new_cleaned_data/recola_valence_2_test.csv\n",
      "Fold 3 - Saved training data to /work/jingyiz4/new_cleaned_data/recola_valence_3_training.csv\n",
      "Fold 3 - Saved validation data to /work/jingyiz4/new_cleaned_data/recola_valence_3_validation.csv\n",
      "Fold 3 - Saved test data to /work/jingyiz4/new_cleaned_data/recola_valence_3_test.csv\n",
      "Fold 4 - Saved training data to /work/jingyiz4/new_cleaned_data/recola_valence_4_training.csv\n",
      "Fold 4 - Saved validation data to /work/jingyiz4/new_cleaned_data/recola_valence_4_validation.csv\n",
      "Fold 4 - Saved test data to /work/jingyiz4/new_cleaned_data/recola_valence_4_test.csv\n",
      "1080\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "There is no overlap.\n",
      "False\n",
      "Fold 1 - Train: (756, 386) Validation: (108, 386) Test: (216, 386)\n",
      "Fold 2 - Train: (756, 386) Validation: (108, 386) Test: (216, 386)\n",
      "Fold 3 - Train: (756, 386) Validation: (108, 386) Test: (216, 386)\n",
      "Fold 0 - Saved training data to /work/jingyiz4/new_cleaned_data/recola_arousal_0_training.csv\n",
      "Fold 0 - Saved validation data to /work/jingyiz4/new_cleaned_data/recola_arousal_0_validation.csv\n",
      "Fold 0 - Saved test data to /work/jingyiz4/new_cleaned_data/recola_arousal_0_test.csv\n",
      "Fold 1 - Saved training data to /work/jingyiz4/new_cleaned_data/recola_arousal_1_training.csv\n",
      "Fold 1 - Saved validation data to /work/jingyiz4/new_cleaned_data/recola_arousal_1_validation.csv\n",
      "Fold 1 - Saved test data to /work/jingyiz4/new_cleaned_data/recola_arousal_1_test.csv\n",
      "Fold 2 - Saved training data to /work/jingyiz4/new_cleaned_data/recola_arousal_2_training.csv\n",
      "Fold 2 - Saved validation data to /work/jingyiz4/new_cleaned_data/recola_arousal_2_validation.csv\n",
      "Fold 2 - Saved test data to /work/jingyiz4/new_cleaned_data/recola_arousal_2_test.csv\n",
      "Fold 3 - Saved training data to /work/jingyiz4/new_cleaned_data/recola_arousal_3_training.csv\n",
      "Fold 3 - Saved validation data to /work/jingyiz4/new_cleaned_data/recola_arousal_3_validation.csv\n",
      "Fold 3 - Saved test data to /work/jingyiz4/new_cleaned_data/recola_arousal_3_test.csv\n",
      "Fold 4 - Saved training data to /work/jingyiz4/new_cleaned_data/recola_arousal_4_training.csv\n",
      "Fold 4 - Saved validation data to /work/jingyiz4/new_cleaned_data/recola_arousal_4_validation.csv\n",
      "Fold 4 - Saved test data to /work/jingyiz4/new_cleaned_data/recola_arousal_4_test.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import os\n",
    "ALL_DATASETS = [\n",
    "            'umeme_arousal', \n",
    "            'umeme_valence', \n",
    "\n",
    "                # 'vreed_av',\n",
    "\n",
    "                # 'iemocap_valence', 'iemocap_arousal',\n",
    "                'recola_valence', \n",
    "                'recola_arousal', \n",
    "                # 'sewa_valence', 'sewa_arousal', \n",
    "                # 'mosi_sentiment',\n",
    "                # 'mosei_sentiment', 'mosei_happiness',\n",
    "                ]\n",
    "data_split = range(5)\n",
    "dataset_rootdir = '/work/jingyiz4/cleaned_data/'\n",
    "new_dataset_rootdir = '/work/jingyiz4/new_cleaned_data/'\n",
    "\n",
    "def check_overlap(list1, list2):\n",
    "    # Convert lists to sets\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "\n",
    "    # Find intersection\n",
    "    overlap = set1.intersection(set2)\n",
    "\n",
    "    # Check if there is any overlap\n",
    "    if overlap:\n",
    "        print(\"There is an overlap.\")\n",
    "        print(\"Overlapping elements:\", overlap)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"There is no overlap.\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "for dataset_name in ALL_DATASETS:\n",
    "\n",
    "    dataset_files = [dataset_rootdir + dataset_name + f'_{0}_{data_type}.csv'\n",
    "                for data_type in ['training', 'validation', 'test']]\n",
    "                \n",
    "    df_list = [pd.read_csv(dataset_file) for dataset_file in dataset_files] \n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    # print(df.head())\n",
    "    print(len(df))\n",
    "\n",
    "\n",
    "    # Parameters\n",
    "    n_splits = 5  # Number of folds\n",
    "    # test_size = 0.2  # Proportion of dataset to include in the test split\n",
    "    validation_size = 0.125  # Proportion of training set to include in the validation set\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=2025)\n",
    "\n",
    "    # Create folds\n",
    "    folds = []\n",
    "    for train_index, test_index in kf.split(df):\n",
    "\n",
    "        print(check_overlap(train_index, test_index))\n",
    "        # Splitting the data into train and test for the current fold\n",
    "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "\n",
    "        # Further split the training data into actual train and validation sets\n",
    "        train, validation = train_test_split(train, test_size=validation_size, random_state=42)\n",
    "        print(check_overlap(train.index, validation.index))\n",
    "\n",
    "        # Store the split data in a tuple\n",
    "        folds.append((train, validation, test))\n",
    "\n",
    "    # Accessing the splits\n",
    "    train_fold_1, val_fold_1, test_fold_1 = folds[0]\n",
    "    train_fold_2, val_fold_2, test_fold_2 = folds[1]\n",
    "    train_fold_3, val_fold_3, test_fold_3 = folds[2]\n",
    "\n",
    "    # Each fold consists of a train, validation, and test subset\n",
    "    print(\"Fold 1 - Train:\", train_fold_1.shape, \"Validation:\", val_fold_1.shape, \"Test:\", test_fold_1.shape)\n",
    "    print(\"Fold 2 - Train:\", train_fold_2.shape, \"Validation:\", val_fold_2.shape, \"Test:\", test_fold_2.shape)\n",
    "    print(\"Fold 3 - Train:\", train_fold_3.shape, \"Validation:\", val_fold_3.shape, \"Test:\", test_fold_3.shape)\n",
    "\n",
    "    for i, (train, val, test) in enumerate(folds):\n",
    "\n",
    "        os.makedirs(new_dataset_rootdir, exist_ok=True)\n",
    "\n",
    "\n",
    "        train_file = os.path.join(new_dataset_rootdir, f\"{dataset_name}_{i}_training.csv\")\n",
    "        val_file = os.path.join(new_dataset_rootdir, f\"{dataset_name}_{i}_validation.csv\")\n",
    "        test_file = os.path.join(new_dataset_rootdir, f\"{dataset_name}_{i}_test.csv\")\n",
    "\n",
    "        train.to_csv(train_file, index=False)\n",
    "        val.to_csv(val_file, index=False)\n",
    "        test.to_csv(test_file, index=False)\n",
    "\n",
    "        print(f\"Fold {i} - Saved training data to {train_file}\")\n",
    "        print(f\"Fold {i} - Saved validation data to {val_file}\")\n",
    "        print(f\"Fold {i} - Saved test data to {test_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d21805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muvi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
