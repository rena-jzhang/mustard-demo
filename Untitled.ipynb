{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59241ff3",
   "metadata": {},
   "source": [
    "### Display dataset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m file_path \u001b[38;5;241m=\u001b[39m files[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Read the CSV file into a DataFrame\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# display(df.head())\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Get the column names\u001b[39;00m\n\u001b[1;32m     34\u001b[0m columns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Specify the directory where your CSV files are located\n",
    "directory = '/results/twoertwe/meta/'\n",
    "\n",
    "# Create an empty DataFrame to store column information\n",
    "column_info = pd.DataFrame(columns=['File', 'Columns', 'FeatNum', 'Unique Y Values'])\n",
    "\n",
    "# Create a dictionary to group files by their prefixes\n",
    "file_groups = defaultdict(list)\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        prefix = filename.split('_')[0]\n",
    "        \n",
    "        # Add the file to the corresponding group\n",
    "        file_groups[prefix].append(file_path)\n",
    "\n",
    "# Iterate through each group and analyze one CSV file from each group\n",
    "for prefix, files in file_groups.items():\n",
    "    # Take the first file from the group (you can modify this logic if needed)\n",
    "    file_path = files[0]\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # display(df.head())\n",
    "    # Get the column names\n",
    "    columns = df.columns.tolist()\n",
    "    \n",
    "    unique_y_values = df['y'].unique().tolist()\n",
    "    \n",
    "    # Add file and column information to the DataFrame\n",
    "    column_info = pd.concat([column_info, pd.DataFrame({'File': [file_path.split('_')[0]], 'Columns': [columns], 'FeatNum': [len(columns)], 'Unique Y Values':[unique_y_values]})], ignore_index=True)\n",
    "\n",
    "grouped_info_data = []\n",
    "\n",
    "# Iterate through each row in column_info\n",
    "for _, row in column_info.iterrows():\n",
    "    file = row['File']\n",
    "    columns = row['Columns']\n",
    "    \n",
    "    # Create a dictionary to store the grouped columns\n",
    "    grouped_columns = {}\n",
    "    \n",
    "    # Iterate through each column and group by prefix\n",
    "    for col in columns:\n",
    "        prefix = col.split('_')[0]\n",
    "        if prefix in grouped_columns:\n",
    "            grouped_columns[prefix].append(col)\n",
    "        else:\n",
    "            grouped_columns[prefix] = [col]\n",
    "            \n",
    "    print(grouped_columns.items())\n",
    "    \n",
    "    # Add the grouped columns and prefix to the list\n",
    "    grouped_info_data.append({'File': file, 'GroupedColumns': list(zip(grouped_columns.keys(), [len(i) for i in grouped_columns.values()]))})\n",
    "\n",
    "grouped_info = pd.DataFrame(grouped_info_data)\n",
    "merged_info = pd.merge(column_info, grouped_info, on='File')\n",
    "\n",
    "display(merged_info)\n",
    "merged_info.to_csv('metadata.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441baec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y  meta  acoustic  language  vision  ecg  eda  mocap\n",
      "0  1     4       140       457     125    0    0      0\n",
      "1  1     3       140       457     125    0    0      0\n",
      "2  1     8       140       457     125    0    0      0\n",
      "3  1     9        52       457     125    0    0      0\n",
      "4  1     3       140         0     125   54   62      0\n",
      "5  1    19       140       457     125    0    0    330\n",
      "6  1     1         0         0      49   18    8      0\n",
      "7  1     3       140       457     125    0    0      0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Columns</th>\n",
       "      <th>FeatNum</th>\n",
       "      <th>Unique Y Values</th>\n",
       "      <th>GroupedColumns</th>\n",
       "      <th>y</th>\n",
       "      <th>meta</th>\n",
       "      <th>acoustic</th>\n",
       "      <th>language</th>\n",
       "      <th>vision</th>\n",
       "      <th>ecg</th>\n",
       "      <th>eda</th>\n",
       "      <th>mocap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/results/twoertwe/meta/mosi</td>\n",
       "      <td>[y, meta_clip, meta_begin, meta_end, meta_id, ...</td>\n",
       "      <td>727</td>\n",
       "      <td>[-2.8, -2.6, -0.8, 1.6, -2.2, -3.0, -0.4, 0.8,...</td>\n",
       "      <td>[(y, 1), (meta, 4), (acoustic, 140), (language...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/results/twoertwe/meta/sewa</td>\n",
       "      <td>[y, meta_begin, meta_end, meta_id, acoustic_op...</td>\n",
       "      <td>726</td>\n",
       "      <td>[0.0055897776, 0.41614386, 0.3779384, 0.350838...</td>\n",
       "      <td>[(y, 1), (meta, 3), (acoustic, 140), (language...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/results/twoertwe/meta/tpot</td>\n",
       "      <td>[y, meta_Evidence, meta_Visual, meta_Language,...</td>\n",
       "      <td>731</td>\n",
       "      <td>[0, 3, 2, 1]</td>\n",
       "      <td>[(y, 1), (meta, 8), (acoustic, 140), (language...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>140</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/results/twoertwe/meta/umeme</td>\n",
       "      <td>[y, meta_arousal_audio, meta_valence_audio, me...</td>\n",
       "      <td>644</td>\n",
       "      <td>[4.7, 2.55, 3.06, 5.31, 3.31, 2.85, 3.5, 4.23,...</td>\n",
       "      <td>[(y, 1), (meta, 9), (acoustic, 52), (language,...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/results/twoertwe/meta/recola</td>\n",
       "      <td>[y, meta_begin, meta_end, meta_id, acoustic_op...</td>\n",
       "      <td>385</td>\n",
       "      <td>[0.024066666, -0.0049866666, 0.060946666, 0.10...</td>\n",
       "      <td>[(y, 1), (meta, 3), (acoustic, 140), (ecg, 54)...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/results/twoertwe/meta/iemocap</td>\n",
       "      <td>[y, meta_begin, meta_end, meta_arousal_T, meta...</td>\n",
       "      <td>1072</td>\n",
       "      <td>[2.0, 3.0, 3.5, 4.0, 2.5, 4.5, 1.5, 1.6667, 2....</td>\n",
       "      <td>[(y, 1), (meta, 19), (acoustic, 140), (languag...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>140</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/results/twoertwe/meta/vreed</td>\n",
       "      <td>[y, meta_id, ecg_Bpm, ecg_HF, ecg_Ibi, ecg_LF,...</td>\n",
       "      <td>77</td>\n",
       "      <td>[1, 0, 3, 2]</td>\n",
       "      <td>[(y, 1), (meta, 1), (ecg, 18), (eda, 8), (visi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/results/twoertwe/meta/mosei</td>\n",
       "      <td>[y, meta_begin, meta_end, meta_id, acoustic_op...</td>\n",
       "      <td>726</td>\n",
       "      <td>[0.0, 1.6666666, 1.3333334, 0.33333334, 0.6666...</td>\n",
       "      <td>[(y, 1), (meta, 3), (acoustic, 140), (language...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>457</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             File  \\\n",
       "0     /results/twoertwe/meta/mosi   \n",
       "1     /results/twoertwe/meta/sewa   \n",
       "2     /results/twoertwe/meta/tpot   \n",
       "3    /results/twoertwe/meta/umeme   \n",
       "4   /results/twoertwe/meta/recola   \n",
       "5  /results/twoertwe/meta/iemocap   \n",
       "6    /results/twoertwe/meta/vreed   \n",
       "7    /results/twoertwe/meta/mosei   \n",
       "\n",
       "                                             Columns FeatNum  \\\n",
       "0  [y, meta_clip, meta_begin, meta_end, meta_id, ...     727   \n",
       "1  [y, meta_begin, meta_end, meta_id, acoustic_op...     726   \n",
       "2  [y, meta_Evidence, meta_Visual, meta_Language,...     731   \n",
       "3  [y, meta_arousal_audio, meta_valence_audio, me...     644   \n",
       "4  [y, meta_begin, meta_end, meta_id, acoustic_op...     385   \n",
       "5  [y, meta_begin, meta_end, meta_arousal_T, meta...    1072   \n",
       "6  [y, meta_id, ecg_Bpm, ecg_HF, ecg_Ibi, ecg_LF,...      77   \n",
       "7  [y, meta_begin, meta_end, meta_id, acoustic_op...     726   \n",
       "\n",
       "                                     Unique Y Values  \\\n",
       "0  [-2.8, -2.6, -0.8, 1.6, -2.2, -3.0, -0.4, 0.8,...   \n",
       "1  [0.0055897776, 0.41614386, 0.3779384, 0.350838...   \n",
       "2                                       [0, 3, 2, 1]   \n",
       "3  [4.7, 2.55, 3.06, 5.31, 3.31, 2.85, 3.5, 4.23,...   \n",
       "4  [0.024066666, -0.0049866666, 0.060946666, 0.10...   \n",
       "5  [2.0, 3.0, 3.5, 4.0, 2.5, 4.5, 1.5, 1.6667, 2....   \n",
       "6                                       [1, 0, 3, 2]   \n",
       "7  [0.0, 1.6666666, 1.3333334, 0.33333334, 0.6666...   \n",
       "\n",
       "                                      GroupedColumns  y  meta  acoustic  \\\n",
       "0  [(y, 1), (meta, 4), (acoustic, 140), (language...  1     4       140   \n",
       "1  [(y, 1), (meta, 3), (acoustic, 140), (language...  1     3       140   \n",
       "2  [(y, 1), (meta, 8), (acoustic, 140), (language...  1     8       140   \n",
       "3  [(y, 1), (meta, 9), (acoustic, 52), (language,...  1     9        52   \n",
       "4  [(y, 1), (meta, 3), (acoustic, 140), (ecg, 54)...  1     3       140   \n",
       "5  [(y, 1), (meta, 19), (acoustic, 140), (languag...  1    19       140   \n",
       "6  [(y, 1), (meta, 1), (ecg, 18), (eda, 8), (visi...  1     1         0   \n",
       "7  [(y, 1), (meta, 3), (acoustic, 140), (language...  1     3       140   \n",
       "\n",
       "   language  vision  ecg  eda  mocap  \n",
       "0       457     125    0    0      0  \n",
       "1       457     125    0    0      0  \n",
       "2       457     125    0    0      0  \n",
       "3       457     125    0    0      0  \n",
       "4         0     125   54   62      0  \n",
       "5       457     125    0    0    330  \n",
       "6         0      49   18    8      0  \n",
       "7       457     125    0    0      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_row(row):\n",
    "    # Initialize an empty dictionary to store the processed data for the row\n",
    "    processed_data = {}\n",
    "    \n",
    "    # Iterate through each cell in the row\n",
    "    for cell in row:\n",
    "        if cell:  # Check if the cell is not empty\n",
    "            column_name = cell[0]  # The first element is the column name\n",
    "            column_value = cell[1]  # Combine the other elements\n",
    "            processed_data[column_name] = column_value\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'col' is the column name\n",
    "# Apply the function to each row\n",
    "processed_rows = merged_info.GroupedColumns.apply(process_row)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(processed_rows.tolist())\n",
    "\n",
    "# If necessary, you can fill NaN values with an appropriate value or method\n",
    "result_df = result_df.fillna(0).astype(int)\n",
    "print(result_df)\n",
    "\n",
    "merged_result = merged_info.merge(\n",
    "result_df.fillna(0), left_index=True, right_index=True)\n",
    "\n",
    "display(merged_result)\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['Columns', 'FeatNum','GroupedColumns']\n",
    "\n",
    "# Remove the specified columns\n",
    "merged_result = merged_result.drop(columns=columns_to_remove)\n",
    "\n",
    "\n",
    "merged_result.to_csv('metadata.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4813c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset sewa_valence, size: 769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import *\n",
    "from mmidataset import custom_collate_fn\n",
    "\n",
    "\n",
    "dataset_rootdir = '/results/twoertwe/meta/'  # Path to your dataset directory\n",
    "\n",
    "batch_size = 32  # Set the batch size\n",
    "dataset_name = 'sewa_valence'\n",
    "data_type = 'test'\n",
    "\n",
    "non_text_features = DATASET_MODALITY[dataset_name]\n",
    "\n",
    "# Create an instance of MMIDataset\n",
    "mmi_dataset = MMIDataset(data_type=data_type, dataset_name=dataset_name, \n",
    "                        dataset_rootdir=dataset_rootdir, feature_list=non_text_features)\n",
    "\n",
    "data_loader = DataLoader(mmi_dataset, batch_size=batch_size, collate_fn = custom_collate_fn)\n",
    "\n",
    "\n",
    "from tests.test_dataset_split import *\n",
    "test_dataset_train_val_test_overlap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5bb98",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def video_processor(video_path):\n",
    "    # Load pretrained ResNet-152 model\n",
    "    model = models.resnet152(pretrained=True)\n",
    "    model = torch.nn.Sequential(*(list(model.children())[:-1])) # Remove the last fully connected layer\n",
    "    model.eval()\n",
    "\n",
    "    # Video frame extraction and preprocessing\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = preprocess_frame(frame)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return torch.empty(0, 2048)  # Return an empty tensor if no frames are extracted\n",
    "\n",
    "    # Convert list of frames to tensor\n",
    "    frames_tensor = torch.stack(frames)\n",
    "    print('frame', frames_tensor)\n",
    "\n",
    "    # Feature extraction\n",
    "    with torch.no_grad():\n",
    "        features = model(frames_tensor)\n",
    "    print('features', features)\n",
    "\n",
    "    features_mean = torch.mean(features, dim=0).unsqueeze(0)\n",
    "\n",
    "    # Flatten features from [N, 2048, 1, 1] to [N, 2048]\n",
    "    features_flattened = torch.flatten(features_mean, start_dim=1)\n",
    "\n",
    "    return features_flattened\n",
    "\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return preprocess(frame)\n",
    "\n",
    "\n",
    "def process_video_data(videos_folder, video_features_path):\n",
    "    video_features = []\n",
    "\n",
    "    for filename in os.listdir(videos_folder):\n",
    "        video_path = os.path.join(videos_folder, filename)\n",
    "        video_feature = video_processor(video_path)\n",
    "        video_features.append(video_feature)\n",
    "            \n",
    "    with open(video_features_path, 'wb') as f:\n",
    "        pickle.dump(video_features, f)\n",
    "\n",
    "    print(f\"Video features saved to {video_features_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281bc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa torch numpy\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_librosa_features(path: str) -> np.ndarray:\n",
    "    y, sr = librosa.load(path)\n",
    "\n",
    "    hop_length = 512  # Set the hop length; at 22050 Hz, 512 samples ~= 23ms\n",
    "\n",
    "    # Remove vocals first\n",
    "    D = librosa.stft(y, hop_length=hop_length)\n",
    "    S_full, phase = librosa.magphase(D)\n",
    "\n",
    "    S_filter = librosa.decompose.nn_filter(S_full, aggregate=np.median, metric=\"cosine\",\n",
    "                                           width=int(librosa.time_to_frames(0.2, sr=sr)))\n",
    "\n",
    "    S_filter = np.minimum(S_full, S_filter)\n",
    "\n",
    "    margin_i, margin_v = 2, 4\n",
    "    power = 2\n",
    "    mask_v = librosa.util.softmask(S_full - S_filter, margin_v * S_filter, power=power)\n",
    "    S_foreground = mask_v * S_full\n",
    "\n",
    "    # Recreate vocal_removal y\n",
    "    new_D = S_foreground * phase\n",
    "    y = librosa.istft(new_D)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # Compute MFCC features from the raw signal\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)  # And the first-order differences (delta features)\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "    S_delta = librosa.feature.delta(S)\n",
    "\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(S=S_full)\n",
    "\n",
    "    audio_feature = np.vstack((mfcc, mfcc_delta, S, S_delta, spectral_centroid))  # combine features\n",
    "\n",
    "    # binning data\n",
    "    jump = int(audio_feature.shape[1] / 10)\n",
    "    return librosa.util.sync(audio_feature, range(1, audio_feature.shape[1], jump))\n",
    "\n",
    "def extract_audio_features(audio_file_path: str) -> torch.Tensor:\n",
    "    # Extract audio seq features using librosa\n",
    "    features = get_librosa_features(audio_file_path).T\n",
    "    \n",
    "    # avg\n",
    "    tensor_features = torch.tensor(features).mean(dim=0).unsqueeze(0)\n",
    "    return tensor_features\n",
    "\n",
    "def process_audio_data(audio_folder, audio_features_path):\n",
    "    audio_features = []\n",
    "\n",
    "    for filename in tqdm(os.listdir(audio_folder), desc=\"Processing audio files\"):\n",
    "        audio_path = os.path.join(audio_folder, filename)\n",
    "        if os.path.isfile(audio_path):\n",
    "            audio_feature = extract_audio_features(audio_path)\n",
    "            audio_features.append(audio_feature)\n",
    "\n",
    "    # Save to a pickle file\n",
    "    with open(audio_features_path, 'wb') as f:\n",
    "        pickle.dump(audio_features, f)\n",
    "    print(f\"Audio features saved to {audio_features_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined dataset paths configuration\n",
    "DATASET_PATHS = {\n",
    "    'datasets/MOSI_small': {\n",
    "        'videos_folder': '/projects/dataset_original/datasets/MOSI_small/Base_data/Videos_Segmented',\n",
    "        'audios_folder': '/projects/dataset_original/datasets/MOSI_small/Base_data/Audio_Segmented'\n",
    "    }\n",
    "\n",
    "    # Add more datasets here if needed\n",
    "}\n",
    "def prepare_dataset_paths(dataset_name):\n",
    "\n",
    "    # Check if the dataset is defined in the configuration\n",
    "    if dataset_name in DATASET_PATHS:\n",
    "        paths = DATASET_PATHS[dataset_name]\n",
    "\n",
    "        # Process video and audio data if their paths are available\n",
    "        if 'videos_folder' in paths:\n",
    "            video_features_path = f'{dataset_name}/video_features.pkl'\n",
    "            process_video_data(paths['videos_folder'], video_features_path)\n",
    "\n",
    "        if 'audios_folder' in paths:\n",
    "            audio_features_path = f'{dataset_name}/audio_features.pkl'\n",
    "            process_audio_data(paths['audios_folder'], audio_features_path)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset {dataset_name} not found in dataset paths\")\n",
    "\n",
    "# Example usage\n",
    "dataset_name = 'datasets/MOSI_small'\n",
    "# prepare_dataset_paths(dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process text and label\n",
    "# !pip install pandas --force-reinstall\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "TEXT_FEATURE_PATH = f'{dataset_name}/text_n_label.csv'\n",
    "\n",
    "csv_file_path = TEXT_FEATURE_PATH\n",
    "\n",
    "def read_text_files(folder_path, df):\n",
    "    text_list = []\n",
    "    label_list = []\n",
    "\n",
    "    filenames = [filename for filename in sorted(os.listdir(folder_path)) if filename.endswith('.txt')]\n",
    "    \n",
    "    print(filenames[:5])\n",
    "    # Iterate over all files in the given folder\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Check if it's a file and not a directory\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                # Read the content and add it to the list\n",
    "                text_list.append(file.read())\n",
    "                \n",
    "        label_list.append(df[df['filename'] == filename.split('.')[0]]['label'][0])\n",
    "\n",
    "    label_list = [f\"{float(number):.2f}\" for number in label_list]\n",
    "\n",
    "    return text_list, label_list\n",
    "\n",
    "\n",
    "def text_label_creation(text_list, label_list, csv_file_path = TEXT_FEATURE_PATH):\n",
    "\n",
    "    assert len(text_list) == len(label_list), \"Text and label lists must have the same length.\"\n",
    "\n",
    "    # Writing to csv file\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header\n",
    "        csvwriter.writerow(['text_input', 'label'])\n",
    "\n",
    "        # Write the data\n",
    "        for text, label in zip(text_list, label_list):\n",
    "            csvwriter.writerow([text, label])\n",
    "\n",
    "    print(f\"CSV file saved to {csv_file_path}\")\n",
    "    \n",
    "csv_path ='/projects/dataset_original/datasets/MOSI_small/Base_data/Labels/boundaries_sentimentint_avg.csv'\n",
    "text_folder = '/projects/dataset_original/datasets/MOSI_small/Base_data/Text_Per_Segment/Final'\n",
    "\n",
    "df = pd.read_csv(csv_path, header=None)\n",
    "headers = ['c1', 'c2', 'c3', 'filename', 'label']\n",
    "df.columns = headers\n",
    "\n",
    "text_list, label_list = read_text_files(text_folder, df)\n",
    "\n",
    "\n",
    "print(text_list[:5], label_list[:5])\n",
    "# text_label_creation(text_list, label_list, csv_file_path = TEXT_FEATURE_PATH)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654e5fd",
   "metadata": {},
   "source": [
    "### Result post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_metrics(true_values, predicted_values):\n",
    "    \"\"\"\n",
    "    Calculate CCC, RMSE, and PCC.\n",
    "    :param true_values: Array of true values\n",
    "    :param predicted_values: Array of predicted values\n",
    "    :return: Concordance Correlation Coefficient, Root Mean Squared Error, Pearson Correlation Coefficient\n",
    "    \"\"\"\n",
    "    # Convert non-numeric values to NaN\n",
    "    true_values = pd.to_numeric(true_values, errors='coerce')\n",
    "    predicted_values = pd.to_numeric(predicted_values, errors='coerce')\n",
    "    \n",
    "    # Remove or impute NaNs (or use np.nanmean, np.nanvar, etc., to handle NaNs)\n",
    "    valid_indices = ~np.isnan(true_values) & ~np.isnan(predicted_values)\n",
    "    true_values = true_values[valid_indices]\n",
    "    predicted_values = predicted_values[valid_indices]\n",
    "\n",
    "    # Calculate CCC\n",
    "    mean_true = np.mean(true_values)\n",
    "    mean_predicted = np.mean(predicted_values)\n",
    "    var_true = np.var(true_values)\n",
    "    var_predicted = np.var(predicted_values)\n",
    "    pearson_corr, _ = pearsonr(true_values, predicted_values)\n",
    "    ccc = (2 * pearson_corr * np.sqrt(var_true) * np.sqrt(var_predicted)) / \\\n",
    "          (var_true + var_predicted + (mean_true - mean_predicted) ** 2)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "\n",
    "    # PCC is the Pearson Correlation Coefficient\n",
    "    pcc = pearson_corr\n",
    "\n",
    "    return ccc, rmse, pcc\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "ALL_DATASETS = [\n",
    "            'umeme_arousal', \n",
    "                # 'vreed_av',\n",
    "\n",
    "                'iemocap_valence', 'iemocap_arousal',\n",
    "                # 'recola_valence', \n",
    "                # 'recola_arousal', \n",
    "                # 'sewa_valence', 'sewa_arousal', \n",
    "                # 'mosi_sentiment',\n",
    "                # 'mosei_sentiment', 'mosei_happiness',\n",
    "                ]\n",
    "\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "num_epoch = 30\n",
    "\n",
    "for task_name in ALL_DATASETS:\n",
    "    best_ccc = -1\n",
    "    best_rmse = float('inf')\n",
    "    best_pcc = -1\n",
    "\n",
    "    for i in range(num_epoch):\n",
    "        csv_file = f'/work/jingyiz4/mustard-demo/results/{task_name}/gpt2_nopretrain_0.0001_2_42_0_unfreeze/predictions_actuals_{i}.csv'\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Assuming the columns are named 'Actual' and 'Prediction'\n",
    "        true_values = df['Actual'].to_numpy()\n",
    "        predicted_values = df['Prediction'].to_numpy()\n",
    "\n",
    "        # Calculate metrics\n",
    "        ccc, rmse, pcc = calculate_metrics(true_values, predicted_values)\n",
    "\n",
    "        # Update best metrics if current epoch is better\n",
    "        if ccc > best_ccc:\n",
    "            best_ccc = ccc\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "        if pcc > best_pcc:\n",
    "            best_pcc = pcc\n",
    "\n",
    "    # Store best results for the task\n",
    "    results.append({\n",
    "        \"Task\": task_name,\n",
    "        \"Modeling\": 'gpt2',\n",
    "        \"Best RMSE\": best_rmse,\n",
    "        \"Best PCC\": best_pcc,\n",
    "        \"Best CCC\": best_ccc,\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42c6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the base directories\n",
    "source_base = \"/projects/dataset_processed\"\n",
    "target_base = \"/work/jingyiz4/datasets/\"\n",
    "\n",
    "# List of subdirectories\n",
    "subdirs = [\"UMEME\", \"MOSI\", \"MOSEI\", \"AVEC16-RECOLA\", \"SEWA\",\n",
    "        #    \"IEMOCAP\"\n",
    "           ]\n",
    "\n",
    "for subdir in subdirs:\n",
    "    source_dir = os.path.join(source_base, subdir, \"twoertwein\")\n",
    "    target_dir = os.path.join(target_base, subdir, \"twoertwein\")\n",
    "\n",
    "    # Create the target directory if it doesn't exist\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    # Copy all Python files\n",
    "    for file in os.listdir(source_dir):\n",
    "        if file.endswith(\".py\"):\n",
    "            shutil.copy2(os.path.join(source_dir, file), target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9482e828",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'python_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpython_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m caching, features\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpython_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_parallel\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'python_tools'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from python_tools import caching, features\n",
    "from python_tools.generic import map_parallel\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/projects/dataset_processed/TPOT/twoertwein\")\n",
    "from extract import extract_liwc, load_liwc\n",
    "\n",
    "# NEW_PATH = '/work/jingyiz4/datasets/UMEME'\n",
    "\n",
    "def extract(file: Path) -> None:\n",
    "    name = file.with_suffix(\".hdf\").name\n",
    "    # openface+opensmile\n",
    "    cache = {}\n",
    "    if file.suffix == \".mp4\":\n",
    "        cache[\"openface\"] = Path(f\"openface/{name}\")\n",
    "    if file.suffix == \".mp3\" or \"Only\" not in file.name:\n",
    "        cache[\"opensmile_eGeMAPSv02\"] = Path(f\"opensmile_eGeMAPSv02/{name}\")\n",
    "        cache[\"opensmile_vad_opensource\"] = Path(f\"opensmile_vad_opensource/{name}\")\n",
    "    features.extract_features(video=file, audio=file, caches=cache)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    map_parallel(\n",
    "        extract,\n",
    "        Path(\"/projects/dataset_original/UMEME/media/\").glob(\"*.mp*\"),\n",
    "        workers=7,\n",
    "    )\n",
    "\n",
    "    sentences = (\n",
    "        \"How can I not\",\n",
    "        \"I’m quite sure that we will find some way or another\",\n",
    "        \"Ella Jorgenson made the pudding\",\n",
    "        \"The floor was completely covered\",\n",
    "        \"They are just going to go ahead regardless\",\n",
    "        \"It has all been scheduled since Wednesday\",\n",
    "        \"I am going shopping\",\n",
    "        \"A preliminary study shows rats to be more inquisitive than once thought\",\n",
    "        \"That’s it the meeting is finished\",\n",
    "        \"I don’t know how she could miss this opportunity\",\n",
    "        \"It is raining outside\",\n",
    "        \"Your dog is insane\",\n",
    "        \"She told me what you did\",\n",
    "        \"Your grandmother is on the phone\",\n",
    "        \"Only I joined her in the ceremony\",\n",
    "    )\n",
    "    data = {\n",
    "        \"file\": [],\n",
    "        \"name\": [],\n",
    "        \"sentence\": [],\n",
    "        \"valence\": [],\n",
    "        \"arousal\": [],\n",
    "        \"dominance\": [],\n",
    "        \"audio\": [],\n",
    "        \"video\": [],\n",
    "    }\n",
    "    for block in (\n",
    "        Path(\"/projects/dataset_original/UMEME/evaluation.txt\")\n",
    "        .read_text()\n",
    "        .split(\"\\n\\n\")\n",
    "    ):\n",
    "        if not block:\n",
    "            continue\n",
    "        name, *details = block.split(\"\\n\")\n",
    "        details = {\n",
    "            detail.split(\":\", 1)[0].strip(): detail.split(\":\", 1)[1].strip()\n",
    "            for detail in details\n",
    "        }\n",
    "\n",
    "        data[\"name\"].append(details[\"speaker\"])\n",
    "        match details[\"modality\"]:\n",
    "            case \"av\":\n",
    "                file = f\"{name}_original.mp4\"\n",
    "            case \"video\":\n",
    "                file = f\"{name}_videoOnly.mp4\"\n",
    "            case \"audio\":\n",
    "                file = f\"{name}_audioOnly.mp3\"\n",
    "            case _:\n",
    "                assert False, _\n",
    "        assert (Path(\"/projects/dataset_original/UMEME/media\") / file).is_file()\n",
    "        data[\"file\"].append(file)\n",
    "        data[\"sentence\"].append(\n",
    "            sentences[int(name.split(\"-\", 1)[0].split(\"S\", 1)[1][:-1]) - 1]\n",
    "        )\n",
    "        data[\"arousal\"].append(float(details[\"act\"].split(\"+\", 1)[0]))\n",
    "        data[\"valence\"].append(float(details[\"val\"].split(\"+\", 1)[0]))\n",
    "        data[\"dominance\"].append(float(details[\"dom\"].split(\"+\", 1)[0]))\n",
    "        data[\"audio\"].append(details.get(\"audio\", \"\"))\n",
    "        data[\"video\"].append(details.get(\"video\", \"\"))\n",
    "\n",
    "    # copy labels of uni-modal ratings but discard their features\n",
    "    data = pd.DataFrame(data)\n",
    "    unimodal = data.loc[data[\"file\"].apply(lambda x: \"Only\" in x)].copy()\n",
    "    unimodal[\"file\"] = unimodal[\"file\"].apply(lambda x: x.split(\".\")[0])\n",
    "    labels = (\"arousal\", \"valence\", \"dominance\")\n",
    "    for key in (\"audio\", \"video\"):\n",
    "        for label in labels:\n",
    "            data[f\"meta_{label}_{key}\"] = float(\"NaN\")\n",
    "    for index, row in data.iterrows():\n",
    "        if \"Only\" in row[\"file\"]:\n",
    "            continue\n",
    "        for key in (\"audio\", \"video\"):\n",
    "            match = unimodal[\"file\"] == f\"{row[key]}_{key}Only\"\n",
    "            if not match.any():\n",
    "                print(f\"{row[key]}_{key}Only\")\n",
    "                continue\n",
    "            assert match.sum() == 1\n",
    "            unimodal_index = match[match].index[0]\n",
    "\n",
    "            for label in labels:\n",
    "                data.loc[index, f\"meta_{label}_{key}\"] = unimodal.loc[\n",
    "                    unimodal_index, label\n",
    "                ]\n",
    "    data = data.loc[data[\"file\"].apply(lambda x: \"Only\" not in x)]\n",
    "\n",
    "    # model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "    # embeddings = pd.DataFrame(\n",
    "    #     model.encode(data[\"sentence\"].str.lower().tolist()), index=data.index\n",
    "    # )\n",
    "\n",
    "    liwc = load_liwc()\n",
    "    liwc_features = extract_liwc(liwc, data[\"sentence\"])\n",
    "\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            data,\n",
    "            # embeddings.add_prefix(\"all_minilm_l12_v2_\"),\n",
    "            liwc_features.add_prefix(\"liwc_\"),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    display(data.head())\n",
    "    # caching.write_hdfs(Path(\"all_minilm_l12_v2.hdf\"), {\"df\": data})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32312d5",
   "metadata": {},
   "source": [
    "### Create latex result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995663e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1122501/269508892.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# }\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# df = pd.DataFrame(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Generate LaTeX table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mlatex_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_grouped_latex_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Task\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Grouped Performance Metrics\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tab:grouped_performance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatex_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/jingyiz4/miniconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_grouped_latex_table(df, group_column, caption=\"Your Table Caption\", label=\"tab:your_label\"):\n",
    "    \"\"\"\n",
    "    Create a LaTeX table with grouped rows based on a specific column.\n",
    "\n",
    "    :param df: Pandas DataFrame to convert\n",
    "    :param group_column: Column name to group by\n",
    "    :param caption: Caption for the LaTeX table\n",
    "    :param label: Label for the LaTeX table\n",
    "    :return: String containing the LaTeX table code\n",
    "    \"\"\"\n",
    "    unique_groups = df[group_column].unique()\n",
    "    grouped = df.groupby(group_column)\n",
    "\n",
    "    latex_table = \"\\\\begin{table}[ht]\\n\\\\centering\\n\\\\begin{tabular}{|l|l|r|r|r|}\\n\\\\hline\\n\"\n",
    "    column_labels = \" & \".join(df.columns) + \" \\\\\\\\\\n\\\\hline\\n\"\n",
    "    latex_table += column_labels\n",
    "\n",
    "    for group in unique_groups:\n",
    "        group_df = grouped.get_group(group)\n",
    "        for i, row in group_df.iterrows():\n",
    "            if i == group_df.index[0]:  # First row of the group\n",
    "                latex_table += f\"\\\\multirow{{{len(group_df)}}}{{*}}{{{row[group_column]}}}\"\n",
    "            latex_table += \" & \" + \" & \".join([str(row[col]) for col in df.columns if col != group_column])\n",
    "            latex_table += \" \\\\\\\\\\n\"\n",
    "            if i == group_df.index[-1]:  # Last row of the group\n",
    "                latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "    latex_table += \"\\\\end{tabular}\\n\"\n",
    "    latex_table += f\"\\\\caption{{{caption}}}\\n\"\n",
    "    latex_table += f\"\\\\label{{{label}}}\\n\"\n",
    "    latex_table += \"\\\\end{table}\"\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Example DataFrame\n",
    "# data = {\n",
    "#     \"Task Name\": [\"Task1\", \"Task1\", \"Task2\", \"Task2\", \"Task2\"],\n",
    "#     \"Modeling\": [\"Model A\", \"Model B\", \"Model A\", \"Model B\", \"Model C\"],\n",
    "#     \"RMSE\": [1.2, 1.3, 1.1, 1.4, 1.5],\n",
    "#     \"PCC\": [0.7, 0.75, 0.65, 0.8, 0.85],\n",
    "#     \"CCC\": [0.9, 0.85, 0.88, 0.86, 0.89]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = create_grouped_latex_table(results_df, \"Task\", caption=\"Grouped Performance Metrics\", label=\"tab:grouped_performance\")\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e78905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muvi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
